{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sanitize(string):\n",
    "    words = string.split(' ')\n",
    "    return words\n",
    "\n",
    "def converter(x):\n",
    "    try:\n",
    "        return ' '.join([x.lower() for x in str(x).split() if x not in stop_words])\n",
    "    except AttributeError:\n",
    "        return None  # or some other value\n",
    "    \n",
    "def whole(x):\n",
    "    return int(round(x))\n",
    "\n",
    "whole(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>title1_tokenized</th>\n",
       "      <th>title2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[What, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[What, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[What, is, the, story, of, Kohinoor, (Koh-i-No...</td>\n",
       "      <td>[What, would, happen, if, the, Indian, governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[How, can, I, increase, the, speed, of, my, in...</td>\n",
       "      <td>[How, can, Internet, speed, be, increased, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Why, am, I, mentally, very, lonely?, How, can...</td>\n",
       "      <td>[Find, the, remainder, when, [math]23^{24}[/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[Which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[Which, fish, would, survive, in, salt, water?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                    title1_tokenized  \\\n",
       "0  [What, is, the, step, by, step, guide, to, inv...   \n",
       "1  [What, is, the, story, of, Kohinoor, (Koh-i-No...   \n",
       "2  [How, can, I, increase, the, speed, of, my, in...   \n",
       "3  [Why, am, I, mentally, very, lonely?, How, can...   \n",
       "4  [Which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                    title2_tokenized  \n",
       "0  [What, is, the, step, by, step, guide, to, inv...  \n",
       "1  [What, would, happen, if, the, Indian, governm...  \n",
       "2  [How, can, Internet, speed, be, increased, by,...  \n",
       "3  [Find, the, remainder, when, [math]23^{24}[/ma...  \n",
       "4    [Which, fish, would, survive, in, salt, water?]  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the csv files \n",
    "\n",
    "quora = pd.read_csv(\"quora_duplicate_questions (1).tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "quora['question1']=quora['question1'].fillna(\"\")\n",
    "quora['question2']=quora['question2'].fillna(\"\")\n",
    "\n",
    "\n",
    "quora['title1_tokenized'] = \\\n",
    "    quora.loc[:, 'question1'] \\\n",
    "         .apply(sanitize)\n",
    "quora['title2_tokenized'] = \\\n",
    "    quora.loc[:, 'question2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "\n",
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>qid1</th> <th>qid2</th> <th>question1</th> <th>question2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0   </td> <td>1   </td> <td>2   </td> <td>What is the step by step guide to invest in share market ...</td> <td>What is the step by step guide to invest in share market?   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>3   </td> <td>4   </td> <td>What is the story of Kohinoor (Koh-i-Noor) Diamond?         </td> <td>What would happen if the Indian government stole the Koh ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>5   </td> <td>6   </td> <td>How can I increase the speed of my internet connection w ...</td> <td>How can Internet speed be increased by hacking through DNS? </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>7   </td> <td>8   </td> <td>Why am I mentally very lonely? How can I solve it?          </td> <td>Find the remainder when [math]23^{24}[/math] is divided  ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>9   </td> <td>10  </td> <td>Which one dissolve in water quikly sugar, salt, methane  ...</td> <td>Which fish would survive in salt water?                     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (404285 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tb = Table()\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"quora_duplicate_questions (1).tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(5):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        Tb=Tb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "Tb.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [What, is, the, step, by, step, guide, to, inv...\n",
       "1    [What, is, the, story, of, Kohinoor, (Koh-i-No...\n",
       "2    [How, can, I, increase, the, speed, of, my, in...\n",
       "3    [Why, am, I, mentally, very, lonely?, How, can...\n",
       "4    [Which, one, dissolve, in, water, quikly, suga...\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dictionary\n",
    "\n",
    "MAX_NUM_WORDS = 20000\n",
    "tokenizer = keras \\\n",
    "    .preprocessing \\\n",
    "    .text \\\n",
    "    .Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "corpus_x1 = quora.title1_tokenized\n",
    "corpus_x2 = quora.title2_tokenized\n",
    "corpus = pd.concat([\n",
    "  corpus_x1, corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "x1 = tokenizer \\\n",
    "    .texts_to_sequences(corpus_x1)\n",
    "x2 = tokenizer \\\n",
    "    .texts_to_sequences(corpus_x2)\n",
    "\n",
    "word_index=tokenizer.word_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max([            #why does seq length change when I change dictionary size?\n",
    "    len(seq) for seq in x1])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     2,     3,     1,  1394,    54,  1394,  2940,\n",
       "            7,   519,     8,   748,   566,     8,    58],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            2,     3,     1,   749,     9, 18336, 13264],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     4,    13,     5,   178,     1,   467,     9,\n",
       "           17,   522,  2556,   165,   128,     6,  7726],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,    16,    66,     5,  3010,\n",
       "          253,  5384,     4,    13,     5,   546,   112],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,    22,    49,  8304,\n",
       "            8,   275, 19661,    12,  2050, 13805, 13531]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len1 = max([\n",
    "    len(seq) for seq in x1])\n",
    "print(max_seq_len1)   \n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 115  #better to have words covered than uncovered\n",
    "x1 = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2 = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x1[:5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dup = quora.is_duplicate\n",
    "\n",
    "y = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(dup)\n",
    "\n",
    "\n",
    "\n",
    "print(len(quora))\n",
    "\n",
    "y[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def foo():\n",
    "    q=[]\n",
    "    p=0\n",
    "    for x in quora.is_duplicate:\n",
    "        if math.isnan(x):\n",
    "            q = np.append(q, p)\n",
    "        p+=1\n",
    "    return q\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  7., 11.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We randomly select 5,000 paraphrases and 5,000 non-paraphrases as the dev set, and sample\n",
    "#another 5,000 paraphrases and 5,000 non-paraphrases as the\n",
    "#test set. We keep the remaining instances as the training set 2\n",
    "\n",
    "label = quora.is_duplicate\n",
    "eq_list = []\n",
    "uneq_list=[]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x in range(len(quora.is_duplicate)):\n",
    "    if label[x]==1:\n",
    "        eq_list = np.append(eq_list, x) \n",
    "    \n",
    "    else:\n",
    "        uneq_list = np.append(uneq_list, x)\n",
    "\n",
    "        \n",
    "eq_list[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_list=eq_list.astype(int)\n",
    "uneq_list=uneq_list.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149263\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(eq_list)\n",
    "random.shuffle(uneq_list)\n",
    "\n",
    "eq_list[:10]\n",
    "print(len(eq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_test_eq = eq_list[:5000]\n",
    "\n",
    "index_test_uneq = uneq_list[:5000]\n",
    "\n",
    "index_dev_eq = eq_list[5000:10000]\n",
    "\n",
    "index_dev_uneq = uneq_list[5000:10000]\n",
    "\n",
    "index_train_eq = eq_list[10000:]\n",
    "\n",
    "index_train_uneq = uneq_list[10000:]\n",
    "\n",
    "index_test = np.append(index_test_eq, index_test_uneq)\n",
    "\n",
    "index_dev = np.append(index_dev_eq, index_dev_uneq)\n",
    "\n",
    "index_train = np.append(index_train_eq, index_train_uneq)\n",
    "\n",
    "random.shuffle(index_test)\n",
    "random.shuffle(index_dev)\n",
    "random.shuffle(index_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "----------\n",
      "(384290, 115)\n",
      "(384290, 115)\n",
      "(384290, 2)\n",
      "----------\n",
      "(10000, 115)\n",
      "(10000, 115)\n",
      "(10000, 2)\n",
      "Test Set\n",
      "[array([1., 0.], dtype=float32), array([1., 0.], dtype=float32), array([0., 1.], dtype=float32), array([0., 1.], dtype=float32), array([0., 1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x1_test = [x1[i] for i in index_test]\n",
    "\n",
    "x2_test = [x2[i] for i in index_test]\n",
    "\n",
    "y_test = [y[i] for i in index_test]\n",
    "\n",
    "\n",
    "x1_dev = [x1[i] for i in index_dev]\n",
    "\n",
    "x2_dev = [x2[i] for i in index_dev]\n",
    "\n",
    "y_dev=[y[i] for i in index_dev]\n",
    "\n",
    "\n",
    "x1_train = [x1[i] for i in index_train]\n",
    "\n",
    "x2_train = [x2[i] for i in index_train]\n",
    "\n",
    "y_train=[y[i] for i in index_train]\n",
    "\n",
    "\n",
    "print(\"Training Set\")\n",
    "print(\"-\" * 10)\n",
    "print(np.shape(x1_train))\n",
    "print(np.shape(x2_train))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "\n",
    "print(\"-\" * 10)\n",
    "print(np.shape(x1_test))\n",
    "print(np.shape(x2_test))\n",
    "print(np.shape(y_test))\n",
    "\n",
    "\n",
    "print(\"Test Set\")\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 115)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 115)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 115, 256)     5120000     input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 256)          394240      embedding_8[0][0]                \n",
      "                                                                 embedding_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 512)          0           bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            1026        concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,515,266\n",
      "Trainable params: 5,515,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM with no GLoVE or zero masking\n",
    "\n",
    "\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "MAX_NUM_WORDS = 20000 #rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 115 #how long one sentence is\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256 #this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('quora_weights.h5', save_best_only=True, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384290 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "384290/384290 [==============================] - 334s 868us/step - loss: 0.5179 - acc: 0.7464 - val_loss: 0.5366 - val_acc: 0.7308\n",
      "Epoch 2/15\n",
      "384290/384290 [==============================] - 308s 802us/step - loss: 0.4519 - acc: 0.7877 - val_loss: 0.5317 - val_acc: 0.7409\n",
      "Epoch 3/15\n",
      "384290/384290 [==============================] - 306s 795us/step - loss: 0.4139 - acc: 0.8077 - val_loss: 0.5069 - val_acc: 0.7532\n",
      "Epoch 4/15\n",
      "384290/384290 [==============================] - 305s 793us/step - loss: 0.3816 - acc: 0.8232 - val_loss: 0.5274 - val_acc: 0.7607\n",
      "Epoch 5/15\n",
      "384290/384290 [==============================] - 313s 815us/step - loss: 0.3504 - acc: 0.8373 - val_loss: 0.5719 - val_acc: 0.7584\n",
      "Epoch 6/15\n",
      "384290/384290 [==============================] - 306s 795us/step - loss: 0.3189 - acc: 0.8495 - val_loss: 0.5986 - val_acc: 0.7558\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x=([np.array(x1_train), np.array(x2_train)]), y=np.array(y_train), batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[earlyStopping, mcp_save], validation_data=([np.array(x1_dev), np.array(x2_dev)], np.array(y_dev)),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"BiLSTM_QQP.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(\n",
    "    [x1_train, x2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no = []\n",
    "err1 = []\n",
    "err2 = []\n",
    "wrongCat = []\n",
    "\n",
    "\n",
    "for x in range(len(predicts)):\n",
    "    if (np.argmax(predicts[x])==(np.argmax(y_train[x]))):\n",
    "        no=np.append(no, x)\n",
    "        err1=np.append(err1, x1_train[x])\n",
    "        err2=np.append(err2, x2_train[x])\n",
    "        wrongCat = np.append(wrongCat, y_train[x])\n",
    "        \n",
    "print(1-(len(wrongCat)/len(x1_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis = Table()\n",
    "\n",
    "\n",
    "error_analysis=error_analysis.with_column(\"id\", no, \"sent1\", err1, \"sent2\", err2, \"classification\", wrongCat)\n",
    "error_analysis\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue = error_analysis.where(\"classification\", are.equal_to(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "NUM_EMBEDDING_DIM = 100\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index)+1, NUM_EMBEDDING_DIM))\n",
    "\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BiLSTM_QQP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
