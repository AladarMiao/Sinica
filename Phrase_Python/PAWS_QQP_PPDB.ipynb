{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sentence1</th> <th>sentence2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>b'Will a message still say blocked if you were delivered ...</td> <td>b'Will a message still say delivered if you were blocked ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>b'How can you treat ocd ? Is there any helpful suggestio ...</td> <td>b'How can you treat OCD ? Is there any helpful suggestio ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>b'If you do not do anything how you are motivated to see ...</td> <td>b'If you do not seek anything how you are motivated to d ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>b'Why is new in system verily constructor not a task ?'     </td> <td>b'Why constructor new in system verilog is not a task ?'    </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>b'What are the most common traffic convictions in Arizon ...</td> <td>b'What are the most common traffic convictions in Arkans ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (11858 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sentence1</th> <th>sentence2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>b'What were the major effects of the cambodia earthquake ...</td> <td>b'What were the major effects of the Iquique earthquake  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>b\"The guy I 'm dating never texts me and I feel like he  ...</td> <td>b\"The guy I 'm dating never wants me and I feel like he  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>b\"How do I make my new phone number as group admin when  ...</td> <td>b\"How do I make my old phone number as group admin when  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>b'Do Mexican women like East Asian men ( Korean , Japane ...</td> <td>b'Do East Asian women like Mexican men ( Korean , Japane ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (664 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_Tb = Table()\n",
    "dev_Tb = Table()\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"dataset/PAWS_QQP/PAWS_QQP_train.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        train_Tb=train_Tb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "train_Tb.show(5)\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"dataset/PAWS_QQP/PAWS_QQP_dev_and_test.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        dev_Tb=dev_Tb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "dev_Tb.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdb_Tb=Table.read_table(\"dataset/ppdb/sanitized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train_Tb.column(\"id\")\n",
    "train_sen1=train_Tb.column(\"sentence1\")\n",
    "train_sen2=train_Tb.column(\"sentence2\")  #PAWS_QQP\n",
    "train_row = train_Tb.num_rows\n",
    "dev_id=dev_Tb.column(\"id\")\n",
    "dev_row=dev_Tb.num_rows\n",
    "dev_sen1=dev_Tb.column(\"sentence1\")\n",
    "dev_sen2=dev_Tb.column(\"sentence2\")\n",
    "train_label = train_Tb.column(\"label\")\n",
    "dev_label=dev_Tb.column(\"label\")\n",
    "\n",
    "phrase = ppdb_Tb.column(\"PHRASE\")\n",
    "paraphrase=ppdb_Tb.column(\"PARAPHRASE\")   #ppdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "PPDB_id = []\n",
    "sent1=[]\n",
    "sent2=[]\n",
    "para_list1=[]\n",
    "para_list2=[]\n",
    "labeling = []\n",
    "\n",
    "ans = []\n",
    "for x in range(len(train_id)):   #index of PAWS_QQP\n",
    "    \n",
    "    for z in range(len(phrase)):  #index of PPDB\n",
    "        if (phrase[z] in train_sen1[x] and paraphrase[z] in train_sen2[x]):\n",
    "            print(phrase[z])\n",
    "            index_list=np.append(index_list, x)\n",
    "            PPDB_id=np.append(PPDB_id, z)\n",
    "            sent1=np.append(sent1, train_sen1[x])\n",
    "            sent2=np.append(sent2, train_sen2[x])\n",
    "            para_list1=np.append(para_list1, phrase[z])\n",
    "            para_list2=np.append(para_list2, paraphrase[z])\n",
    "            labeling = np.append(labeling, train_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset = Table().with_column(\"TRAIN_PAWS_QQP_id\", index_list, \"PPDB_id\", PPDB_id, \"sent1\", sent1, \"sent2\", sent2, \"paraphrase1\", para_list1, \"paraphrase2\", para_list2, \"label\", labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_TRAIN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "PPDB_id = []\n",
    "sent1=[]\n",
    "sent2=[]\n",
    "para_list1=[]\n",
    "para_list2=[]\n",
    "labeling = []\n",
    "\n",
    "ans = []\n",
    "for x in range(len(dev_id)):   #index of PAWS_QQP\n",
    "    \n",
    "    for z in range(len(phrase)):  #index of PPDB\n",
    "        if (phrase[z] in dev_sen1[x] and paraphrase[z] in dev_sen2[x]):\n",
    "            print(phrase[z])\n",
    "            index_list=np.append(index_list, x)\n",
    "            PPDB_id=np.append(PPDB_id, z)\n",
    "            sent1=np.append(sent1, dev_sen1[x])\n",
    "            sent2=np.append(sent2, dev_sen2[x])\n",
    "            para_list1=np.append(para_list1, phrase[z])\n",
    "            para_list2=np.append(para_list2, paraphrase[z])\n",
    "            labeling = np.append(labeling, dev_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset = Table().with_column(\"DEV_PAWS_QQP_id\", index_list, \"PPDB_id\", PPDB_id, \"sent1\", sent1, \"sent2\", sent2, \"paraphrase1\", para_list1, \"paraphrase2\", para_list2, \"label\", labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_TRAIN-Copy1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_TRAIN.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV-Copy1.csv\")\n",
    "dataframe.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>DEV_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>84905.0 </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality </td> <td> quality    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>129607.0</td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality </td> <td> quality    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>72492.0 </td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with   </td> <td> start with </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>366448.0</td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with   </td> <td> start with </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (96 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list1=[]\n",
    "list2=[]\n",
    "\n",
    "label_data = Table()\n",
    "with open(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.tsv\", 'r') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(6):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        label_data=label_data.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "\n",
    "label_data.show(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sent1=label_data.column(\"sent1\")\n",
    "sent2=label_data.column(\"sent2\")\n",
    "para1=label_data.column(\"paraphrase1\")\n",
    "para2=label_data.column(\"paraphrase2\")\n",
    "\n",
    "gg = [x.split() for x in sent1]\n",
    "hh = [x.split() for x in sent2]\n",
    "ii = [x.split() for x in para1]\n",
    "jj = [x.split() for x in para2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[]\n",
    "for x in range(len(gg)):\n",
    "    labels1.append(spit_label(gg[x], ii[x], len(ii[x]),len(ii[x]), []))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=[]\n",
    "for x in range(len(hh)):\n",
    "    labels2.append(spit_label(hh[x], jj[x], len(jj[x]),len(jj[x]), []))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined1=[]\n",
    "for x in labels1:\n",
    "    joined1.append(\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined2=[]\n",
    "for x in labels2:\n",
    "    joined2.append(\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>DEV_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>84905.0 </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality         </td> <td> quality     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>129607.0</td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality         </td> <td> quality     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>72492.0 </td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with           </td> <td> start with  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>366448.0</td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with           </td> <td> start with  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>22.0           </td> <td>543619.0</td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td> much better          </td> <td> much        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25.0           </td> <td>487239.0</td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td> far left             </td> <td> left        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29.0           </td> <td>284980.0</td> <td>b\"What are the reasons for SAARC 's failure as regional  ...</td> <td>b\"What are the reasons for SAARC 's failure as common or ...</td> <td> economic cooperation </td> <td> cooperation </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>56.0           </td> <td>459668.0</td> <td>b'I want to be a child psychologist , what qualification ...</td> <td>b'I want to become a child psychologist , what qualifica ...</td> <td> become one           </td> <td> be          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>57.0           </td> <td>71262.0 </td> <td>b'Why are beautiful girls so rude all the time ? I saw a ...</td> <td>b'Why are rude girls so beautiful all the time ? I saw a ...</td> <td> very rude            </td> <td> rude        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>57.0           </td> <td>494710.0</td> <td>b'Why are beautiful girls so rude all the time ? I saw a ...</td> <td>b'Why are rude girls so beautiful all the time ? I saw a ...</td> <td> go away              </td> <td> away        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (90 rows omitted)</p>"
      ],
      "text/plain": [
       "DEV_PAWS_QQP_id | PPDB_id  | sent1                                                        | sent2                                                        | paraphrase1            | paraphrase2\n",
       "3.0             | 84905.0  | b\"Why ca n't countries afford high quality products , bu ... | b\"Why ca n't countries afford China 's high quality prod ... |  high quality          |  quality\n",
       "3.0             | 129607.0 | b\"Why ca n't countries afford high quality products , bu ... | b\"Why ca n't countries afford China 's high quality prod ... |  high quality          |  quality\n",
       "11.0            | 72492.0  | b'How do I start learning electronic music production ?  ... | b'How do I begin learning electronic music production ?  ... |  begin with            |  start with\n",
       "11.0            | 366448.0 | b'How do I start learning electronic music production ?  ... | b'How do I begin learning electronic music production ?  ... |  begin with            |  start with\n",
       "22.0            | 543619.0 | b\"I 'm currently working for a Big 4 as an Advanced Tax  ... | b\"I 'm currently working for a Big 4 as an Advanced Tax  ... |  much better           |  much\n",
       "25.0            | 487239.0 | b'In Nevada when pulling out of a parking lot , can you  ... | b'In Nevada when pulling out of a parking lot , can you  ... |  far left              |  left\n",
       "29.0            | 284980.0 | b\"What are the reasons for SAARC 's failure as regional  ... | b\"What are the reasons for SAARC 's failure as common or ... |  economic cooperation  |  cooperation\n",
       "56.0            | 459668.0 | b'I want to be a child psychologist , what qualification ... | b'I want to become a child psychologist , what qualifica ... |  become one            |  be\n",
       "57.0            | 71262.0  | b'Why are beautiful girls so rude all the time ? I saw a ... | b'Why are rude girls so beautiful all the time ? I saw a ... |  very rude             |  rude\n",
       "57.0            | 494710.0 | b'Why are beautiful girls so rude all the time ? I saw a ... | b'Why are rude girls so beautiful all the time ? I saw a ... |  go away               |  away\n",
       "... (90 rows omitted)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data=label_data.with_columns(\"labels1\", joined1, \"labels2\", joined2)\n",
    "label_data=label_data.to_df()\n",
    "label_data.to_csv(\"dataset/Phrase_Level/LABELED_PAWS_QQP_DEV.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def spit_label(split_sent, para_split, ori_length, length, listy):\n",
    "       \n",
    "    \n",
    "        if para_split[0]==split_sent[0]:\n",
    "            \n",
    "            if ori_length==1:\n",
    "                listy.append(\"S\")\n",
    "                for x in range(len(split_sent)-1):\n",
    "                    listy.append(\"O\")\n",
    "                return listy    \n",
    "            \n",
    "            elif ori_length==length:\n",
    "                listy.append(\"B\")\n",
    "                return spit_label(split_sent[1:], para_split[1:], ori_length, length-1, listy)\n",
    "                \n",
    "            elif length==1:\n",
    "                listy.append(\"E\")\n",
    "                for x in range(len(split_sent)-1):\n",
    "                    listy.append(\"O\")\n",
    "                return listy\n",
    "            \n",
    "            else:\n",
    "                listy.append(\"I\")\n",
    "                return spit_label(split_sent[1:], para_split[1:], ori_length, length-1, listy)\n",
    "                \n",
    "        else:\n",
    "            listy.append(\"O\")\n",
    "            return spit_label(split_sent[1:], para_split, ori_length, length, listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=\"\".join(\"he \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
