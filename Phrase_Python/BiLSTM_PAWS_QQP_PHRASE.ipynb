{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(string):\n",
    "    words = string.split(' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 16 01:38:41 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8    20W / 250W |  10827MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "\n",
    "train = pd.read_csv(\"dataset/Phrase_Level/PAWS_QQP/LABELED_PAWS_QQP_TRAIN.tsv\", sep='\\t')\n",
    "dev = pd.read_csv(\"dataset/Phrase_Level/PAWS_QQP/LABELED_PAWS_QQP_DEV.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "print(train[:5])\n",
    "\n",
    "train['title1_tokenized'] = \\\n",
    "    train.loc[:, 'sent1'] \\\n",
    "         .apply(sanitize)\n",
    "train['title2_tokenized'] = \\\n",
    "    train.loc[:, 'sent2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "dev['title1_tokenized'] = \\\n",
    "    dev.loc[:, 'sent1'] \\\n",
    "         .apply(sanitize)\n",
    "dev['title2_tokenized'] = \\\n",
    "    dev.loc[:, 'sent2'] \\\n",
    "         .apply(sanitize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRAIN_PAWS_QQP_id</th>\n",
       "      <th>PPDB_id</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>paraphrase1</th>\n",
       "      <th>paraphrase2</th>\n",
       "      <th>labels1</th>\n",
       "      <th>labels2</th>\n",
       "      <th>Ground Label</th>\n",
       "      <th>title1_tokenized</th>\n",
       "      <th>title2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>44326</td>\n",
       "      <td>b'What are the most common traffic convictions...</td>\n",
       "      <td>b'What are the most common traffic convictions...</td>\n",
       "      <td>most common</td>\n",
       "      <td>common</td>\n",
       "      <td>O O O B E O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>O O O O S O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'What, are, the, most, common, traffic, conv...</td>\n",
       "      <td>[b'What, are, the, most, common, traffic, conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>103288</td>\n",
       "      <td>b'Which are in your opinion the most beautiful...</td>\n",
       "      <td>b'Which are in your opinion the most depressin...</td>\n",
       "      <td>most beautiful</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>O O O O O O B E O O O O O O O O</td>\n",
       "      <td>O O O O O O O O O O O S O O O O</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'Which, are, in, your, opinion, the, most, b...</td>\n",
       "      <td>[b'Which, are, in, your, opinion, the, most, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>316010</td>\n",
       "      <td>b'Is nuclear energy renewable energy ?'</td>\n",
       "      <td>b\"`` Is nuclear energy `` renewable energy `` ...</td>\n",
       "      <td>nuclear energy</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>O B E O O O</td>\n",
       "      <td>O O S O O O O O O O</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'Is, nuclear, energy, renewable, energy, ?']</td>\n",
       "      <td>[b\"``, Is, nuclear, energy, ``, renewable, ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>526060</td>\n",
       "      <td>b'What ancient units would definitely win in a...</td>\n",
       "      <td>b'What numerous modern units would definitely ...</td>\n",
       "      <td>fight against</td>\n",
       "      <td>fight</td>\n",
       "      <td>O O O O O O O O O B E O O O O</td>\n",
       "      <td>O O O O O O O O O O S O O O O</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'What, ancient, units, would, definitely, wi...</td>\n",
       "      <td>[b'What, numerous, modern, units, would, defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>43995</td>\n",
       "      <td>b'I have only a very nice startup idea but I m...</td>\n",
       "      <td>b'I have only a very good startup idea but I m...</td>\n",
       "      <td>very nice</td>\n",
       "      <td>nice</td>\n",
       "      <td>O O O O B E O O O O O O O O O O O O O</td>\n",
       "      <td>O O O O O O O O O O O O S O O O O O O</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'I, have, only, a, very, nice, startup, idea...</td>\n",
       "      <td>[b'I, have, only, a, very, good, startup, idea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TRAIN_PAWS_QQP_id  PPDB_id  \\\n",
       "0           0                  4    44326   \n",
       "1           1                 10   103288   \n",
       "2           2                 14   316010   \n",
       "3           3                 18   526060   \n",
       "4           4                 61    43995   \n",
       "\n",
       "                                               sent1  \\\n",
       "0  b'What are the most common traffic convictions...   \n",
       "1  b'Which are in your opinion the most beautiful...   \n",
       "2            b'Is nuclear energy renewable energy ?'   \n",
       "3  b'What ancient units would definitely win in a...   \n",
       "4  b'I have only a very nice startup idea but I m...   \n",
       "\n",
       "                                               sent2       paraphrase1  \\\n",
       "0  b'What are the most common traffic convictions...      most common    \n",
       "1  b'Which are in your opinion the most depressin...   most beautiful    \n",
       "2  b\"`` Is nuclear energy `` renewable energy `` ...   nuclear energy    \n",
       "3  b'What numerous modern units would definitely ...    fight against    \n",
       "4  b'I have only a very good startup idea but I m...        very nice    \n",
       "\n",
       "   paraphrase2                                      labels1  \\\n",
       "0      common   O O O B E O O O O O O O O O O O O O O O O O   \n",
       "1   beautiful               O O O O O O B E O O O O O O O O   \n",
       "2     nuclear                                   O B E O O O   \n",
       "3       fight                 O O O O O O O O O B E O O O O   \n",
       "4        nice         O O O O B E O O O O O O O O O O O O O   \n",
       "\n",
       "                                       labels2  Ground Label  \\\n",
       "0  O O O O S O O O O O O O O O O O O O O O O O             0   \n",
       "1              O O O O O O O O O O O S O O O O             1   \n",
       "2                          O O S O O O O O O O             1   \n",
       "3                O O O O O O O O O O S O O O O             0   \n",
       "4        O O O O O O O O O O O O S O O O O O O             1   \n",
       "\n",
       "                                    title1_tokenized  \\\n",
       "0  [b'What, are, the, most, common, traffic, conv...   \n",
       "1  [b'Which, are, in, your, opinion, the, most, b...   \n",
       "2     [b'Is, nuclear, energy, renewable, energy, ?']   \n",
       "3  [b'What, ancient, units, would, definitely, wi...   \n",
       "4  [b'I, have, only, a, very, nice, startup, idea...   \n",
       "\n",
       "                                    title2_tokenized  \n",
       "0  [b'What, are, the, most, common, traffic, conv...  \n",
       "1  [b'Which, are, in, your, opinion, the, most, d...  \n",
       "2  [b\"``, Is, nuclear, energy, ``, renewable, ene...  \n",
       "3  [b'What, numerous, modern, units, would, defin...  \n",
       "4  [b'I, have, only, a, very, good, startup, idea...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-649e60b9770d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m## The first entry is the word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## These are the vecotrs representing the embedding for the word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('GloVEs/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0] ## The first entry is the word\n",
    "    coefs = np.asarray(values[1:], dtype='float32') ## These are the vecotrs representing the embedding for the word\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('GloVe data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"b'What are the most common traffic convictions in Arizona , and how does the severity of the convictions differ in Arkansas ?'\",\n",
       "       \"b'Which are in your opinion the most beautiful and the most depressing truths about life ?'\",\n",
       "       \"b'Is nuclear energy renewable energy ?'\", ...,\n",
       "       \"b'Did Barnacle really raise $ 7M just to close a few months later ?'\",\n",
       "       'b\"What are the major flaws with Donald Trump \\'s and Hillary Clinton \\'s foreign policy agendas ?\"',\n",
       "       'b\"`` Why do many Europeans think Americans are `` dumb `` even when the U.S. has the highest GDP in the world ? \\'\\'\"'],\n",
       "      dtype='<U244')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Tb.column(\"sent1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize sentences\n",
    "def normalize_and_split(sentence):\n",
    "    s=sentence.split()\n",
    "    l=[x.lower() for x in s]\n",
    "    first_word=(l[0])[2:]\n",
    "    l[0]=first_word\n",
    "    return l\n",
    "\n",
    "\n",
    "#tokenize labels\n",
    "\n",
    "def t_label(str):\n",
    "    ret=[]\n",
    "    s = str.split() #split into individual alphabets\n",
    "    for x in s:\n",
    "        if x=='O':\n",
    "            ret.append(0)\n",
    "        else:\n",
    "            ret.append(1)\n",
    "    for t in range(60-len(s)): \n",
    "        ret.append(0)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'liking', 'itt']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_and_split(\"b'I Am LiKINg iTt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Tb=Table.read_table(\"dataset/Phrase_Level/PAWS_QQP/LABELED_PAWS_QQP_TRAIN.tsv\")\n",
    "dev_Tb=Table.read_table(\"dataset/Phrase_Level/PAWS_QQP/LABELED_PAWS_QQP_DEV.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Unnamed: 0</th> <th>TRAIN_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th> <th>labels1</th> <th>labels2</th> <th>Ground Label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>4                </td> <td>44326  </td> <td>b'What are the most common traffic convictions in Arizon ...</td> <td>b'What are the most common traffic convictions in Arkans ...</td> <td> most common       </td> <td> common       </td> <td>O O O B E O O O O O O O O O O O O O O O O O                 </td> <td>O O O O S O O O O O O O O O O O O O O O O O                 </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1         </td> <td>10               </td> <td>103288 </td> <td>b'Which are in your opinion the most beautiful and the m ...</td> <td>b'Which are in your opinion the most depressing and the  ...</td> <td> most beautiful    </td> <td> beautiful    </td> <td>O O O O O O B E O O O O O O O O                             </td> <td>O O O O O O O O O O O S O O O O                             </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2         </td> <td>14               </td> <td>316010 </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td> nuclear energy    </td> <td> nuclear      </td> <td>O B E O O O                                                 </td> <td>O O S O O O O O O O                                         </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3         </td> <td>18               </td> <td>526060 </td> <td>b'What ancient units would definitely win in a 1v1 fight ...</td> <td>b'What numerous modern units would definitely win in a 1 ...</td> <td> fight against     </td> <td> fight        </td> <td>O O O O O O O O O B E O O O O                               </td> <td>O O O O O O O O O O S O O O O                               </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5         </td> <td>61               </td> <td>464375 </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td> very nice         </td> <td> nice         </td> <td>O O O O B E O O O O O O O O O O O O O                       </td> <td>O O O O O O O O O O O O S O O O O O O                       </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6         </td> <td>65               </td> <td>566357 </td> <td>b'Do women feel more heat than men , given that they wea ...</td> <td>b'Do women feel less heat than men , given that they wea ...</td> <td> surface area      </td> <td> surface      </td> <td>O O O O O O O O O O O O O O O O O B E O O O O               </td> <td>O O O O O O O O O O O O O O O O O S O O O O O               </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7         </td> <td>82               </td> <td>321222 </td> <td>b'Why does volumetric strain volume of a solid body alwa ...</td> <td>b'Why does volumetric strain volume of a solid body alwa ...</td> <td> give an example   </td> <td> example      </td> <td>O O O O O O O O O O O O O O O O O O O B I E O               </td> <td>O O O O O O O O O O O O O O O O O O O O O S O               </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8         </td> <td>119              </td> <td>44326  </td> <td>b'What are the most common fee structures charged for PP ...</td> <td>b'What are the most common fee structures used for PPC M ...</td> <td> most common       </td> <td> common       </td> <td>O O O B E O O O O O O O O O O O O O O                       </td> <td>O O O O S O O O O O O O O O O O O O O                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9         </td> <td>133              </td> <td>560981 </td> <td>b\"I just turned 13 and I was about 5 '4 . How much shoul ...</td> <td>b\"I just turned 13 and I 'm around 5 '4 . How much shoul ...</td> <td> around 150        </td> <td> about 150    </td> <td>O O O O O O O O O O O O O O O O O O O B E O O O O O O       </td> <td>O O O O O O O O O O O O O O O O O O O B E O O O O O O       </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11        </td> <td>143              </td> <td>184768 </td> <td>b\"`` Is 1 month too early to say `` I love you `` ? What ...</td> <td>b'Is 1 month too early to say I love you ? What is the n ...</td> <td> too early         </td> <td> early        </td> <td>O O O O B E O O O O O O O O O O O O O O O O O O             </td> <td>O O O O S O O O O O O O O O O O O O O O                     </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>12        </td> <td>166              </td> <td>21353  </td> <td>b'I have been lifting very heavy for 11 months , but the ...</td> <td>b'I have been lifting pretty heavy for 11 months , but t ...</td> <td> very heavy        </td> <td> heavy        </td> <td>O O O O B E O O O O O O O O O O O                           </td> <td>O O O O O S O O O O O O O O O O O                           </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14        </td> <td>173              </td> <td>198808 </td> <td>b'How do I show the value of jtree check box and get it  ...</td> <td>b'How do I get the value of jtree check box and show it  ...</td> <td> somewhere else    </td> <td> somewhere    </td> <td>O O O O O O O O O O O O O B E O O O O                       </td> <td>O O O O O O O O O O O O O S O O O O O                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>15        </td> <td>179              </td> <td>126949 </td> <td>b'Why do other-made cars like Mercedes-Benz , BMW feel v ...</td> <td>b'Why do German-made cars like Mercedes-Benz , BMW feel  ...</td> <td> very solid        </td> <td> solid        </td> <td>O O O O O O O O O B E O O O O O O O O                       </td> <td>O O O O O O O O O O S O O O O O O O O                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>18        </td> <td>181              </td> <td>281940 </td> <td>b\"Why do people want Hillary Clinton to be president whe ...</td> <td>b\"Why do people want Obama to be president when it 's ju ...</td> <td> 's just           </td> <td> just         </td> <td>O O O O O O O O O O O B E O O O O O O O O O                 </td> <td>O O O O O O O O O O O S O O O O O O O O O O                 </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19        </td> <td>189              </td> <td>273990 </td> <td>b'Is the open parser API Instapaper ? If not is there so ...</td> <td>b'Is the Instapaper parser API open ? If not is there so ...</td> <td> something similar </td> <td> similar      </td> <td>O O O O O O O O O O O B E O O O O O O O O O O O O O O O  ...</td> <td>O O O O O O O O O O O O S O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21        </td> <td>192              </td> <td>479155 </td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>b\"Why do we feel like we should break something when we  ...</td> <td> 're happy         </td> <td> are happy    </td> <td>O O O O O O O O O O O O O O O O O O O O B E O               </td> <td>O O O O O O O O O O O O O O O O O O O O B E O               </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>23        </td> <td>194              </td> <td>507097 </td> <td>b'Which type of relationship is less than friendship and ...</td> <td>b'Which type of relationship is more than friendship and ...</td> <td> less than         </td> <td> is more than </td> <td>O O O O O B E O O O O O O                                   </td> <td>O O O O B I E O O O O O O                                   </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24        </td> <td>204              </td> <td>136503 </td> <td>b'If you had a chance to become someone else who would y ...</td> <td>b'If you had a chance to be someone else who would you b ...</td> <td> someone else      </td> <td> someone      </td> <td>O O O O O O O B E O O O O O O O                             </td> <td>O O O O O O O S O O O O O O O O                             </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>27        </td> <td>207              </td> <td>408259 </td> <td>b'I think abolishing these very much necessary reservati ...</td> <td>b'I think abolishing these really high reservations for  ...</td> <td> very much         </td> <td> much         </td> <td>O O O O B E O O O O O O O O O O O O O O O O O O O O O O O   </td> <td>O O O O O O O O O O O O O O O O S O O O O O O O O O O O O   </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29        </td> <td>249              </td> <td>537727 </td> <td>b'Is sexual dimorphism enough to conclude that gender eq ...</td> <td>b'Is sexual dimorphism enough to conclude that gender eq ...</td> <td> gender equality   </td> <td> equality     </td> <td>O O O O O O O B E O O O                                     </td> <td>O O O O O O O O S O O O                                     </td> <td>1           </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (771 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Unnamed: 0</th> <th>DEV_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th> <th>labels1</th> <th>labels2</th> <th>Ground Label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1         </td> <td>3              </td> <td>129607 </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality         </td> <td> quality       </td> <td>O O O O O B E O O O O O O O O O O O O O O O O O O O         </td> <td>O O O O O O O O S O O O O O O O O O O O O O O O O O O O     </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3         </td> <td>11             </td> <td>366448 </td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with           </td> <td> start with    </td> <td>O O O O O O O O O O O B E O O O O O O O O O O O O O O O  ...</td> <td>O O O O O O O O O O O B E O O O O O O O O O O O O O O O  ...</td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4         </td> <td>22             </td> <td>543619 </td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td> much better          </td> <td> much          </td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5         </td> <td>25             </td> <td>487239 </td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td> far left             </td> <td> left          </td> <td>O O O O O O O O O O O O O O O O O O B E O O O O O O O O  ...</td> <td>O O O O O O O O O O O O O O S O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6         </td> <td>29             </td> <td>284980 </td> <td>b\"What are the reasons for SAARC 's failure as regional  ...</td> <td>b\"What are the reasons for SAARC 's failure as common or ...</td> <td> economic cooperation </td> <td> cooperation   </td> <td>O O O O O O O O O O O O O O O B E O O O O O O O             </td> <td>O O O O O O O O O O O O O O O O O O O O O O S O             </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7         </td> <td>56             </td> <td>459668 </td> <td>b'I want to be a child psychologist , what qualification ...</td> <td>b'I want to become a child psychologist , what qualifica ...</td> <td> become one           </td> <td> be            </td> <td>O O O O O O O O O O O O O O B E O O O O O O O O O O O O O   </td> <td>O O O O O O O O O O O O O O S O O O O O O O O O O O O O O   </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9         </td> <td>57             </td> <td>494710 </td> <td>b'Why are beautiful girls so rude all the time ? I saw a ...</td> <td>b'Why are rude girls so beautiful all the time ? I saw a ...</td> <td> go away              </td> <td> away          </td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11        </td> <td>61             </td> <td>65644  </td> <td>b\"What is the name of the creepiest horror movie you 've ...</td> <td>b\"What is the name of the scariest horror movie you 've  ...</td> <td> ever seen            </td> <td> 've ever seen </td> <td>O O O O O O O O O O O B E O O O O O O O                     </td> <td>O O O O O O O O O O B I E O O O O O O O                     </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>15        </td> <td>62             </td> <td>408259 </td> <td>b'I am an electrical engineering student.I am very much  ...</td> <td>b'Am an electrical engineering student , am very much in ...</td> <td> very much            </td> <td> much          </td> <td>O O O O O O O B E O O O O O O O O O O O O O O O O O O       </td> <td>O O O O O O O O S O O O O O O O O O O O O O O O O O O       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>16        </td> <td>70             </td> <td>573133 </td> <td>b\"What is the purpose of life ? What 's life actually ab ...</td> <td>b\"What 's the purpose of life ? What is life actually ab ...</td> <td> 's life              </td> <td> life          </td> <td>O O O O O O O O B E O O O                                   </td> <td>O O O O O S O O O O O O O                                   </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>18        </td> <td>82             </td> <td>198808 </td> <td>b'Why does people here in Quora still ask some questions ...</td> <td>b'Why does people here in Quora still ask some questions ...</td> <td> somewhere else       </td> <td> somewhere     </td> <td>O O O O O O O O O O O O O O O O O O O O O B E O O O O       </td> <td>O O O O O O O O O O O O O O O S O O O O O O O O O O O       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19        </td> <td>87             </td> <td>239527 </td> <td>b'How can we earn money online easily without any kind o ...</td> <td>b'How can We earn money easily on online without any kin ...</td> <td> earn money           </td> <td> earn          </td> <td>O O O B E O O O O O O O O                                   </td> <td>O O O S O O O O O O O O O O                                 </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>20        </td> <td>101            </td> <td>194412 </td> <td>b\"My JBL flip 3 has stopped working the moment I did a s ...</td> <td>b\"My JBL flip 3 has stopped working the moment I did a s ...</td> <td> 's not               </td> <td> not           </td> <td>O O O O O O O O O O O O O O O O O O O O B E O O O O O O     </td> <td>O O O O O O O O O O O O O O O O O O O O O S O O O O O O     </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>22        </td> <td>112            </td> <td>73636  </td> <td>b'What are the most efficient real time audio filtering  ...</td> <td>b'What are the most efficient real time audio filtering  ...</td> <td> most efficient       </td> <td> efficient     </td> <td>O O O B E O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>O O O O S O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>23        </td> <td>131            </td> <td>350671 </td> <td>b'How do you feel about white people adopting black chil ...</td> <td>b'How do you feel about black people adopting white chil ...</td> <td> white people         </td> <td> white         </td> <td>O O O O O B E O O O O                                       </td> <td>O O O O O O O O S O O                                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24        </td> <td>132            </td> <td>33208  </td> <td>b'What courses ( for good jobs ) are most important to b ...</td> <td>b'What courses ( for professional electrical and electro ...</td> <td> most important       </td> <td> important     </td> <td>O O O O O O O O B E O O O O O O O O O                       </td> <td>O O O O O O O O O O O O S O O O O O O                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>26        </td> <td>135            </td> <td>73636  </td> <td>b'What are most efficient real time audio filtering algo ...</td> <td>b'What are most efficient real time audio filtering algo ...</td> <td> most efficient       </td> <td> efficient     </td> <td>O O B E O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>O O O S O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>27        </td> <td>139            </td> <td>244468 </td> <td>b\"How much can a top code boot camp graduate expect to e ...</td> <td>b\"How much can a recent code boot camp graduate expect t ...</td> <td> work experience      </td> <td> experience    </td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>O O O O O O O O O O O O O O O O O O O O O O O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28        </td> <td>143            </td> <td>302476 </td> <td>b'Why am I unable to cancel recently booked tickets that ...</td> <td>b'Why am I unable to see recently booked tickets that I  ...</td> <td> wish to see          </td> <td> wish          </td> <td>O O O O O O O O O O O B I E O O O O O                       </td> <td>O O O O O O O O O O O S O O O O O O O                       </td> <td>0           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29        </td> <td>165            </td> <td>141426 </td> <td>b'Can someone listen to only Metal ? ( Not ACDC and Led  ...</td> <td>b'Can someone listen to Not Metal ? ( only ACDC and Led  ...</td> <td> anyone else          </td> <td> anyone        </td> <td>O O O O O O O O O O O O O O O O O O O O O B E O O O O O  ...</td> <td>O O O O O O O O O O O O O O O O O O O O O S O O O O O O  ...</td> <td>0           </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (43 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if maintain only one extraction per pair; drop those repeats\n",
    "\n",
    "to_drop=[]\n",
    "to_drop2=[]\n",
    "id = train_Tb.column(1)\n",
    "id2=dev_Tb.column(1)\n",
    "\n",
    "\n",
    "for x in range(train_Tb.num_rows-1):\n",
    "    if id[x]==id[x+1]:\n",
    "        to_drop.append(x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "for x in range(dev_Tb.num_rows-1):\n",
    "    if id2[x]==id2[x+1]:\n",
    "        to_drop2.append(x)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "train_Tb=train_Tb.exclude(to_drop)             \n",
    "train_Tb.show(20)\n",
    "\n",
    "dev_Tb=dev_Tb.exclude(to_drop2)             \n",
    "dev_Tb.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize and tokenize sentences\n",
    "\n",
    "train_Tb_sen1=train_Tb.apply(normalize_and_split, \"sent1\")\n",
    "train_Tb_sen2=train_Tb.apply(normalize_and_split, \"sent2\")\n",
    "train_Tb_labels1=train_Tb.apply(t_label, \"labels1\")\n",
    "train_Tb_labels2=train_Tb.apply(t_label, \"labels2\")\n",
    "\n",
    "dev_Tb_sen1=dev_Tb.apply(normalize_and_split, \"sent1\")\n",
    "dev_Tb_sen2=dev_Tb.apply(normalize_and_split, \"sent2\")\n",
    "dev_Tb_labels1=dev_Tb.apply(t_label, \"labels1\")\n",
    "dev_Tb_labels2=dev_Tb.apply(t_label, \"labels2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTb=train_Tb.with_columns(\"sent1_token\", train_Tb_sen1, \"sent2_token\", train_Tb_sen2, \"label1_token\", train_Tb_labels1, \"label2_token\", train_Tb_labels2)\n",
    "devTb=dev_Tb.with_columns(\"sent1_token\", dev_Tb_sen1, \"sent2_token\", dev_Tb_sen2,\"label1_token\", dev_Tb_labels1, \"label2_token\", dev_Tb_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "57\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "max=0\n",
    "for x in trainTb.column(\"sent1_token\"):\n",
    "    if max<len(x):\n",
    "        max=len(x)\n",
    "print(max)\n",
    "\n",
    "max=0\n",
    "for x in trainTb.column(\"sent2_token\"):\n",
    "    if max<len(x):\n",
    "        max=len(x)\n",
    "print(max)\n",
    "\n",
    "max=0\n",
    "for x in devTb.column(\"sent1_token\"):\n",
    "    if max<len(x):\n",
    "        max=len(x)\n",
    "print(max)\n",
    "\n",
    "max=0\n",
    "for x in devTb.column(\"sent2_token\"):\n",
    "    if max<len(x):\n",
    "        max=len(x)\n",
    "print(max)\n",
    "\n",
    "#max seq length say 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl1=trainTb.column(\"label1_token\")\n",
    "tl2=trainTb.column(\"label2_token\")\n",
    "dl1=devTb.column(\"label1_token\")\n",
    "dl2=devTb.column(\"label2_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "1708\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "MAX_NUM_WORDS = 1000\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "\n",
    "train_corpus = np.append(trainTb.column(\"sent1_token\"), trainTb.column(\"sent2_token\"))\n",
    "\n",
    "#create a dictionary\n",
    "\n",
    "tokenizer = keras \\\n",
    "    .preprocessing \\\n",
    "    .text \\\n",
    "    .Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(train_corpus)\n",
    "tokenizer.texts_to_sequences(train_corpus)\n",
    "\n",
    "x1_train = tokenizer \\\n",
    "    .texts_to_sequences(train_Tb_sen1)\n",
    "x2_train = tokenizer \\\n",
    "    .texts_to_sequences(train_Tb_sen2)\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "\n",
    "\n",
    "dev_corpus = np.append(devTb.column(\"sent1_token\"), devTb.column(\"sent2_token\"))\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(dev_corpus)\n",
    "tokenizer.texts_to_sequences(dev_corpus)\n",
    "x1_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_Tb_sen1)\n",
    "x2_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_Tb_sen2)\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x1_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
       "        12,   2,  28, 116, 166,  91,   6, 562,   7,   5,  18,  35,   2,\n",
       "       167,  15,   2,  91, 136,   6, 160,   1], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More code adapted from the keras reference (https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py)\n",
    "# prepare embedding matrix \n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "## EMBEDDING_DIM =  ## seems to need to match the embeddings_index dimension\n",
    "EMBEDDING_DIM = 300\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word) ## This references the loaded embeddings dictionary\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(HAttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(HAttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 60, 300)      300300      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 60, 256)      439296      embedding_2[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 60, 256)      439296      embedding_2[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "h_att_layer_3 (HAttLayer)       (None, 256)          77400       bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "h_att_layer_4 (HAttLayer)       (None, 256)          77400       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 60)           0           h_att_layer_3[0][0]              \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 60)           0           h_att_layer_4[0][0]              \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 60)           3660        dot_1[0][0]                      \n",
      "                                                                 dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,337,352\n",
      "Trainable params: 1,037,052\n",
      "Non-trainable params: 300,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM with glove\n",
    "\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = EMBEDDING_DIM\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "BiLSTM1 = Bidirectional(LSTM(NUM_LSTM_UNITS, return_sequences=True))\n",
    "\n",
    "BiLSTM2 = Bidirectional(LSTM(NUM_LSTM_UNITS, return_sequences=True))\n",
    "\n",
    "top_output = BiLSTM1(top_embedded)\n",
    "\n",
    "bm_output = BiLSTM2(bm_embedded)\n",
    "\n",
    "\n",
    "modelHA_top = HAttLayer(attention_dim=NUM_EMBEDDING_DIM)(top_output)\n",
    "\n",
    "\n",
    "modelHA_bm = HAttLayer(attention_dim=NUM_EMBEDDING_DIM)(bm_output)         #Attention Layer\n",
    "\n",
    "\n",
    "a = dot([modelHA_top, top_output], axes=-1)\n",
    "\n",
    "\n",
    "b = dot([modelHA_bm, bm_output], axes=-1)\n",
    "\n",
    "dense =  Dense(\n",
    "    units=60, \n",
    "    activation='sigmoid')\n",
    "\n",
    "predictions1 = dense(a)\n",
    "\n",
    "predictions2 = dense(b)\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=[predictions1, predictions2])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('Phrase_Models_H5/PAWS_QQP_PHRASE', save_best_only=True,  verbose=1, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 16 00:43:28 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8    20W / 250W |  10827MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 791 samples, validate on 63 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[30720,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node h_att_layer_4/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_1/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-47c97642ed97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x=[x1_train, x2_train], y=[tl1, tl2], batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[mcp_save], validation_data=([x1_dev, x2_dev], [dl1, dl2]),\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[30720,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node h_att_layer_4/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_1/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x1_train, x2_train], y=[tl1, tl2], batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[mcp_save], validation_data=([x1_dev, x2_dev], [dl1, dl2]),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"BiLSTM_PAWS_QQP.h5\")        ##first attempt\n",
    "print(\"Saved model to disk\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"BiLSTM_PAWS_QQP.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicts = model.predict(\n",
    "    [x1_train, x2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11863\n"
     ]
    }
   ],
   "source": [
    "print(len(predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7814212256596139\n"
     ]
    }
   ],
   "source": [
    "real1=train.sentence1\n",
    "real2=train.sentence2\n",
    "realCat=train.label\n",
    "no = []\n",
    "err1 = []\n",
    "err2 = []\n",
    "wrongCat = []\n",
    "\n",
    "\n",
    "for x in range(len(predicts)):\n",
    "    if (np.argmax(predicts[x])!=(train.label[x])):\n",
    "        no=np.append(no, x)\n",
    "        err1=np.append(err1, real1[x])\n",
    "        err2=np.append(err2, real2[x])\n",
    "        wrongCat = np.append(wrongCat, realCat[x])\n",
    "print(1-(len(wrongCat)/len(predicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>b'How can you treat ocd ? Is there any helpful suggestio ...</td> <td>b'How can you treat OCD ? Is there any helpful suggestio ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7   </td> <td>b'What are some beautiful lines to comment on Beautiful  ...</td> <td>b'What are some Beautiful lines to comment on beautiful  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8   </td> <td>b'Can small dogs breed with large dogs ?'                   </td> <td>b'Can small dogs breed with large dogs ?'                   </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>15  </td> <td>b'What should I solve and what or how should I revise fo ...</td> <td>b'What should I revise and what or how should I solve fo ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>20  </td> <td>b'How is the relative ratio of brain waves ( alpha/beta/ ...</td> <td>b'How is the ratio of relative brain waves ( alpha/beta/ ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24  </td> <td>b'Headbreak : What can I do to prevent heart break night ...</td> <td>b'Headbreak : What can I do to prevent heart break night ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25  </td> <td>b'When is latent heat positive ?'                           </td> <td>b'When is latent heat positive ?'                           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35  </td> <td>b'How do I prepare for cognizant campus placement online ...</td> <td>b\"How do I prepare for Cognizant 's online campus placem ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>40  </td> <td>b'Which city is better to choose in India to settle from ...</td> <td>b'Which city is better to settle in India to choose from ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53  </td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>59  </td> <td>b'How do you write an algorithm to find the sum of the f ...</td> <td>b'How do you write an algorithm to find the sum of the f ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61  </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>67  </td> <td>b'What should a mechanical engineer do besides doing col ...</td> <td>b'What should a mechanical engineer do besides studying  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>73  </td> <td>b'How can entropy of two reversible process be same , be ...</td> <td>b'How can entropy of two same process be reversible , be ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>83  </td> <td>b'During muscle gain program , Heavy weight with more re ...</td> <td>b'During muscle gain program , Heavy weight with less re ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>85  </td> <td>b'When does the second batch of training for freshers in ...</td> <td>b'When does the first batch of training for freshers in  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>105 </td> <td>b'It is possible to apply at the Diversity Immigrant Vis ...</td> <td>b'It is possible to get at the Diversity Immigrant Visa  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>106 </td> <td>b\"Why do n't audiobooks create Text-to-speech technology ...</td> <td>b\"Why do n't audiobooks use Text-to-speech technology to ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>108 </td> <td>b'I have polycythemia . Can I qualify for government job ...</td> <td>b'I have polycythemia can I apply for government job can ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>109 </td> <td>b'If I see a video on YouTube , does the owner of the vi ...</td> <td>b'If I watch a video on YouTube , does the owner of the  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>111 </td> <td>b'Who should they cast if they remake Friends in Bollywo ...</td> <td>b'Who should they cast if they remake Friends in Bollywo ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>113 </td> <td>b\"I want to learn piano but I do n't have the basic know ...</td> <td>b\"I want to learn piano but I do n't have the basic know ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>120 </td> <td>b'Can you shoot a Dangerous Human easily death with only ...</td> <td>b'Can you shoot a Dangerous Human easily death with only ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>123 </td> <td>b'Why Are angels shown as having wings ? are they ever s ...</td> <td>b'Why are angels shown as having wings ? Are they ever s ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>134 </td> <td>b\"I have to apply fresh passport for my wife and childre ...</td> <td>b\"I have to apply fresh passport for my wife and childre ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (2563 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_analysis = Table()\n",
    "\n",
    "\n",
    "error_analysis = error_analysis.with_column(\"id\", no, \"sent1\", err1, \"sent2\", err2, \"label\", wrongCat)\n",
    "\n",
    "\n",
    "#false POSITIVE: swap two words\n",
    "#false negative: swap two specific nouns\n",
    "error_analysis.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>b'How can you treat ocd ? Is there any helpful suggestio ...</td> <td>b'How can you treat OCD ? Is there any helpful suggestio ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7   </td> <td>b'What are some beautiful lines to comment on Beautiful  ...</td> <td>b'What are some Beautiful lines to comment on beautiful  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8   </td> <td>b'Can small dogs breed with large dogs ?'                   </td> <td>b'Can small dogs breed with large dogs ?'                   </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24  </td> <td>b'Headbreak : What can I do to prevent heart break night ...</td> <td>b'Headbreak : What can I do to prevent heart break night ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25  </td> <td>b'When is latent heat positive ?'                           </td> <td>b'When is latent heat positive ?'                           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1967 rows omitted)</p>"
      ],
      "text/plain": [
       "id   | sent1                                                        | sent2                                                        | label\n",
       "1    | b'How can you treat ocd ? Is there any helpful suggestio ... | b'How can you treat OCD ? Is there any helpful suggestio ... | 1\n",
       "7    | b'What are some beautiful lines to comment on Beautiful  ... | b'What are some Beautiful lines to comment on beautiful  ... | 1\n",
       "8    | b'Can small dogs breed with large dogs ?'                    | b'Can small dogs breed with large dogs ?'                    | 1\n",
       "13   | b'Are Indian IT services companies like Tech Mahindra/ W ... | b'Are Indian IT services companies like Wipro/TCS/Tech . ... | 1\n",
       "14   | b'Is nuclear energy renewable energy ?'                      | b\"`` Is nuclear energy `` renewable energy `` ? ''\"          | 1\n",
       "21   | b'How can I make an android app using Python 3 ? Is ther ... | b'How can I develop an android app using Python 3 ? Is t ... | 1\n",
       "24   | b'Headbreak : What can I do to prevent heart break night ... | b'Headbreak : What can I do to prevent heart break night ... | 1\n",
       "25   | b'When is latent heat positive ?'                            | b'When is latent heat positive ?'                            | 1\n",
       "28   | b\"What does the phrase 'Do you feel me ' mean ?\"             | b\"What does the phrase `Do you feel me'mean ?\"               | 1\n",
       "29   | b'What are some unexpected things first-time visitors to ... | b'What are some unexpected things , first-time visitors  ... | 1\n",
       "... (1967 rows omitted)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
