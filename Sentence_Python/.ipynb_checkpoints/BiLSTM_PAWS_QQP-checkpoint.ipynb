{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 9,

   "execution_count": 1,

   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(string):\n",
    "    words = string.split(' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  9 02:04:50 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   46C    P8     8W / 200W |    185MiB /  8118MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          sentence1  \\\n",
      "0   1  b'What were the major effects of the cambodia ...   \n",
      "1   2  b\"The guy I 'm dating never texts me and I fee...   \n",
      "\n",
      "                                           sentence2  label  \\\n",
      "0  b'What were the major effects of the Iquique e...      0   \n",
      "1  b\"The guy I 'm dating never wants me and I fee...      0   \n",
      "\n",
      "                                    title1_tokenized  \\\n",
      "0  [b'What, were, the, major, effects, of, the, c...   \n",
      "1  [b\"The, guy, I, 'm, dating, never, texts, me, ...   \n",
      "\n",
      "                                    title2_tokenized  \n",
      "0  [b'What, were, the, major, effects, of, the, I...  \n",
      "1  [b\"The, guy, I, 'm, dating, never, wants, me, ...  \n"
     ]
    }
   ],
   "source": [
    "#read csv\n",
    "\n",
    "train = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_train.tsv\", sep='\\t')\n",
    "dev = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_dev_and_test.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_dev_and_test.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "train['title1_tokenized'] = \\\n",
    "    train.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "train['title2_tokenized'] = \\\n",
    "    train.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "dev['title1_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "dev['title2_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "test['title1_tokenized'] = \\\n",
    "    test.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "test['title2_tokenized'] = \\\n",
    "    test.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "print(dev[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          sentence1  \\\n",
      "0   1  b'What were the major effects of the cambodia ...   \n",
      "1   2  b\"The guy I 'm dating never texts me and I fee...   \n",
      "\n",
      "                                           sentence2  label  \\\n",
      "0  b'What were the major effects of the Iquique e...      0   \n",
      "1  b\"The guy I 'm dating never wants me and I fee...      0   \n",
      "\n",
      "                                    title1_tokenized  \\\n",
      "0  [b'What, were, the, major, effects, of, the, c...   \n",
      "1  [b\"The, guy, I, 'm, dating, never, texts, me, ...   \n",
      "\n",
      "                                    title2_tokenized  \n",
      "0  [b'What, were, the, major, effects, of, the, I...  \n",
      "1  [b\"The, guy, I, 'm, dating, never, wants, me, ...  \n"
     ]
    }
   ],
   "source": [
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23726\n",
      "26402\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = keras \\\n",
    "    .preprocessing \\\n",
    "    .text \\\n",
    "    .Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "train_corpus_x1 = train.title1_tokenized\n",
    "train_corpus_x2 = train.title2_tokenized\n",
    "train_corpus = pd.concat([\n",
    "    train_corpus_x1, train_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(train_corpus)\n",
    "tokenizer.texts_to_sequences(train_corpus)\n",
    "x1_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x1)\n",
    "x2_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x2)\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dev_corpus_x1 = dev.title1_tokenized\n",
    "dev_corpus_x2 = dev.title2_tokenized\n",
    "dev_corpus = pd.concat([\n",
    "    dev_corpus_x1, dev_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(dev_corpus)\n",
    "tokenizer.texts_to_sequences(dev_corpus)\n",
    "x1_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x1)\n",
    "x2_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x2)\n",
    "\n",
    "\n",
    "test_corpus_x1 = test.title1_tokenized\n",
    "test_corpus_x2 = test.title2_tokenized\n",
    "test_corpus = pd.concat([\n",
    "    test_corpus_x1, test_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(test_corpus)\n",
    "tokenizer.texts_to_sequences(test_corpus)\n",
    "x1_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x1)\n",
    "x2_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_seq_len1 = max([\n",
    "    len(seq) for seq in x1_train])\n",
    "print(max_seq_len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1850,\n",
       "        215,    9,  101,  689,  297, 4957,   71,    5,    9,  120,   47,\n",
       "        108,   28,   54, 1034,   84,   71,   52,   50,    9,  166,  259,\n",
       "        108,  718,   71,  108, 1037,   71,    5,  853,   71,   20,   59,\n",
       "         12,    9,  120,   79,  103,   19], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50  #better to have words covered than uncovered\n",
    "x1_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x1_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x1_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x2_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "y_train = train.label\n",
    "\n",
    "y_train = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_train, num_classes=2)\n",
    "\n",
    "\n",
    "y_dev = dev.label\n",
    "\n",
    "y_dev = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_dev, num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "y_test = test.label\n",
    "\n",
    "y_test = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_test, num_classes=2)\n",
    "\n",
    "x1_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cos similarity value to last elem of word embedding\n",
    "x1_test_cos=[]\n",
    "x2_test_cos=[]\n",
    "x1_train_cos=[]\n",
    "x2_train_cos=[]\n",
    "x1_dev_cos=[]\n",
    "x2_dev_cos=[]\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "def cos_sim(vec1, vec2):\n",
    "    return (1 - spatial.distance.cosine(vec1, vec2))\n",
    "\n",
    "for x in range(len(y_train)):\n",
    "    \n",
    "    \n",
    "    cos_train=cos_sim(x1_train[x], x2_train[x])\n",
    "    \n",
    "    \n",
    "    x1_train_cos.append(np.append(x1_train[x], cos_train))\n",
    "    x2_train_cos.append(np.append(x2_train[x], cos_train))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for x in range(len(y_test)):\n",
    "    cos_dev=cos_sim(x1_dev[x], x2_dev[x])\n",
    "    cos_test=cos_sim(x1_test[x], x2_test[x])\n",
    "    x1_test_cos.append(np.append(x1_test[x], cos_test))\n",
    "    x2_test_cos.append(np.append(x2_test[x], cos_test))\n",
    "    x1_dev_cos.append(np.append(x1_dev[x], cos_dev))\n",
    "    x2_dev_cos.append(np.append(x2_dev[x], cos_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11863"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1_train_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 50, 256)      2560000     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 256)          394240      embedding_4[0][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            1026        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,955,266\n",
      "Trainable params: 2,955,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM?\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP.h5', save_best_only=True,  verbose=1, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 51, 256)      2560000     input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 256)          394240      embedding_6[0][0]                \n",
      "                                                                 embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4           dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,954,244\n",
      "Trainable params: 2,954,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity\n",
    "\n",
    "\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = dot(\n",
    "    [top_output, bm_output], \n",
    "    axes=1, normalize = True)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_cos_sim.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 51, 256)      2560000     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 256)          394240      embedding_3[0][0]                \n",
      "                                                                 embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            4           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,954,244\n",
      "Trainable params: 2,954,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM with last cos_sim element concatenated?\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 51 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "\n",
    "top_output = shared_lstm(top_embedded)\n",
    "\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_concat_sim_cos.h5', save_best_only=True,  verbose=1, monitor='val_acc', mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(HAttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(HAttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 51, 256)      2560000     input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 51, 256)      394240      embedding_10[0][0]               \n",
      "                                                                 embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "h_att_layer_17 (HAttLayer)      (None, 256)          66048       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "h_att_layer_18 (HAttLayer)      (None, 256)          66048       bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 51)           0           h_att_layer_17[0][0]             \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 51)           0           h_att_layer_18[0][0]             \n",
      "                                                                 bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 102)          0           dot_7[0][0]                      \n",
      "                                                                 dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dense (Dense)                   (None, 2)            206         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,086,542\n",
      "Trainable params: 3,086,542\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#attention model\n",
    "\n",
    "#last elem cos sim + attention\n",
    "\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 51 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)        \n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(          \n",
    "    bm_input)                           #embedding layer\n",
    "\n",
    "shared_LSTM = Bidirectional(LSTM(NUM_LSTM_UNITS, return_sequences=True)) \n",
    "\n",
    "top_output = shared_LSTM(top_embedded)\n",
    "\n",
    "bm_output = shared_LSTM(bm_embedded)   #BiLSTM layer\n",
    "\n",
    "\n",
    "modelHA_top = HAttLayer(attention_dim=NUM_EMBEDDING_DIM)(top_output)\n",
    "\n",
    "modelHA_bm = HAttLayer(attention_dim=NUM_EMBEDDING_DIM)(bm_output)         #Attention Layer\n",
    "\n",
    "a = dot([modelHA_top, top_output], axes=-1)\n",
    "\n",
    "b = dot([modelHA_bm, bm_output], axes=-1)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [a,b], \n",
    "    axis=-1)                                        #concatenate layer\n",
    "\n",
    "#new_merged = keras.layers.Reshape((-1, 2))(merged)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=2, name='Dense')\n",
    "predictions = dense(merged)                                     #dense\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=[predictions])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_simcos_attention.h5', save_best_only=True,  verbose=1, monitor='val_acc', mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11863 samples, validate on 669 samples\n",
      "Epoch 1/30\n",
      "11863/11863 [==============================] - 16s 1ms/step - loss: 10.3941 - acc: 0.3157 - val_loss: 10.9391 - val_acc: 0.2825\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28251, saving model to BiLSTM_PAWS_QQP_simcos_attention.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3c9ea0f4b08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x=[x1_train_cos, x2_train_cos], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[earlyStopping, mcp_save], validation_data=([x1_dev_cos, x2_dev_cos], y_dev),\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 'optimizer_config': {\n\u001b[1;32m    131\u001b[0m                     \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 },\n\u001b[1;32m    134\u001b[0m                 \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         config = {'lr': float(K.get_value(self.lr)),\n\u001b[0m\u001b[1;32m    518\u001b[0m                   \u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                   \u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m     \"\"\"\n\u001b[0;32m-> 2407\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1693\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \"\"\"\n\u001b[0;32m-> 1695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x1_train_cos, x2_train_cos], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[earlyStopping, mcp_save], validation_data=([x1_dev_cos, x2_dev_cos], y_dev),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BiLSTM_PAWS_QQP_concat_sim_cos.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicts = model.predict(\n",
    "    [x1_train_cos, x2_train_cos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11863"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[:5]\n",
    "len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075276068448116\n"
     ]
    }
   ],
   "source": [
    "real1=train.sentence1\n",
    "real2=train.sentence2\n",
    "realCat=train.label\n",
    "no = []\n",
    "err1 = []\n",
    "err2 = []\n",
    "wrongCat = []\n",
    "\n",
    "\n",
    "for x in range(len(predicts)):\n",
    "    if (np.argmax(predicts[x])!=(train.label[x])):\n",
    "       \n",
    "            no=np.append(no, x)\n",
    "            err1=np.append(err1, real1[x])\n",
    "            err2=np.append(err2, real2[x])\n",
    "            wrongCat = np.append(wrongCat, realCat[x])\n",
    "    \n",
    "        \n",
    "print(1-(len(wrongCat)/len(predicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19  </td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35  </td> <td>b'How do I prepare for cognizant campus placement online ...</td> <td>b\"How do I prepare for Cognizant 's online campus placem ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53  </td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61  </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>78  </td> <td>b'Which CPU should I buy , an Intel or an AMD ?'            </td> <td>b'Which CPU should I buy , an AMD or an Intel ?'            </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>93  </td> <td>b'If one were in the desert with no water except one gal ...</td> <td>b'If one were in the desert with no water except one gal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>139 </td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>143 </td> <td>b\"`` Is 1 month too early to say `` I love you `` ? What ...</td> <td>b'Is 1 month too early to say I love you ? What is the n ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>147 </td> <td>b'I filled the wrong AADHAR enrollment number in the mai ...</td> <td>b'I filled the wrong AADHAR enrollment number in the onl ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>149 </td> <td>b\"I 'm liberal , how would you convince me to be conserv ...</td> <td>b\"I 'm a 'Conservative ' , how would you convince me to  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>150 </td> <td>b'What is the worst thing that has happened to you for b ...</td> <td>b'What is the best thing that has happened to you for be ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>183 </td> <td>b'Can the pro-choice position provide a scientific and r ...</td> <td>b'Can the pro-choice position provide a rational and sci ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>192 </td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>204 </td> <td>b'If you had a chance to become someone else who would y ...</td> <td>b'If you had a chance to be someone else who would you b ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>208 </td> <td>b'What are the top grade levels and titles at different  ...</td> <td>b'What are the different grade levels and titles at top  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>214 </td> <td>b'How similar is Cantonese to Putonghua ?'                  </td> <td>b'How is Cantonese similar to Putonghua ?'                  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>232 </td> <td>b'Also plz share the best material to learn selenium tes ...</td> <td>b'Also please share the best material to learn selenium  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>247 </td> <td>b'What is the difference between standard deviation and  ...</td> <td>b'What is the difference between mean deviation and stan ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>256 </td> <td>b'Why do tamil people hate tamilian brahmin so much ?'      </td> <td>b'Why do tamilian people hate tamil brahmin so much ?'      </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>265 </td> <td>b'What is difference between the extended version and th ...</td> <td>b'What is difference between the theatrical version and  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>273 </td> <td>b'I have got admission from IIM Lucknow and am expecting ...</td> <td>b'I have got admission from IIM Lucknow and I am expecti ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>274 </td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>284 </td> <td>b'Should I shower with cold water or warm water after wo ...</td> <td>b'Should I shower with warm water or cold water after wo ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>295 </td> <td>b'How do you describe a poor and a rich person ?'           </td> <td>b'How do you describe a rich and a poor person ?'           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>317 </td> <td>b\"If Pakistan does controlled a large part of Kashmir ca ...</td> <td>b\"If Pakistan has controlled a large part of Kashmir cal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1067 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0.7873219253\n",
    "error_analysis = Table()\n",
    "\n",
    "\n",
    "error_analysis = error_analysis.with_column(\"id\", no, \"sent1\", err1, \"sent2\", err2, \"label\", wrongCat)\n",
    "\n",
    "\n",
    "#false POSITIVE: swap two words\n",
    "#false negative: swap two specific nouns\n",
    "error_analysis.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19  </td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35  </td> <td>b'How do I prepare for cognizant campus placement online ...</td> <td>b\"How do I prepare for Cognizant 's online campus placem ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53  </td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61  </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>78  </td> <td>b'Which CPU should I buy , an Intel or an AMD ?'            </td> <td>b'Which CPU should I buy , an AMD or an Intel ?'            </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>93  </td> <td>b'If one were in the desert with no water except one gal ...</td> <td>b'If one were in the desert with no water except one gal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>139 </td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>143 </td> <td>b\"`` Is 1 month too early to say `` I love you `` ? What ...</td> <td>b'Is 1 month too early to say I love you ? What is the n ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>147 </td> <td>b'I filled the wrong AADHAR enrollment number in the mai ...</td> <td>b'I filled the wrong AADHAR enrollment number in the onl ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>183 </td> <td>b'Can the pro-choice position provide a scientific and r ...</td> <td>b'Can the pro-choice position provide a rational and sci ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>192 </td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>204 </td> <td>b'If you had a chance to become someone else who would y ...</td> <td>b'If you had a chance to be someone else who would you b ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>214 </td> <td>b'How similar is Cantonese to Putonghua ?'                  </td> <td>b'How is Cantonese similar to Putonghua ?'                  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>232 </td> <td>b'Also plz share the best material to learn selenium tes ...</td> <td>b'Also please share the best material to learn selenium  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>247 </td> <td>b'What is the difference between standard deviation and  ...</td> <td>b'What is the difference between mean deviation and stan ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>256 </td> <td>b'Why do tamil people hate tamilian brahmin so much ?'      </td> <td>b'Why do tamilian people hate tamil brahmin so much ?'      </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>265 </td> <td>b'What is difference between the extended version and th ...</td> <td>b'What is difference between the theatrical version and  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>273 </td> <td>b'I have got admission from IIM Lucknow and am expecting ...</td> <td>b'I have got admission from IIM Lucknow and I am expecti ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>274 </td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>284 </td> <td>b'Should I shower with cold water or warm water after wo ...</td> <td>b'Should I shower with warm water or cold water after wo ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>295 </td> <td>b'How do you describe a poor and a rich person ?'           </td> <td>b'How do you describe a rich and a poor person ?'           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>317 </td> <td>b\"If Pakistan does controlled a large part of Kashmir ca ...</td> <td>b\"If Pakistan has controlled a large part of Kashmir cal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>333 </td> <td>b'Which Bollywood movie has a well crafted , very effect ...</td> <td>b'Which Bollywood movie has a very effective , well craf ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>354 </td> <td>b'I want to do biotechnology from abroad which country s ...</td> <td>b'I want to do biotechnology from abroad which country s ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>355 </td> <td>b'Which study pattern should I follow to prepare for COS ...</td> <td>b'Which pattern of study I should follow to prepare COST ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (876 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_analysis.where(\"label\", are.equal_to(1)).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
