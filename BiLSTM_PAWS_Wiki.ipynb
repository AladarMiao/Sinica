{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 20 07:15:11 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 26%   48C    P8     9W / 200W |    185MiB /  8118MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(string):\n",
    "    words = string.split(' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the test set\n",
    "testTb = Table()\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"test.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        testTb=testTb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "testX = testTb.select(1, 2)\n",
    "testY = testTb.select(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the training set\n",
    "tb = Table()\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"train.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        tb=tb.with_columns(list1[0][ele], list2[ele])\n",
    "        \n",
    "\n",
    "\n",
    "trainX = tb.select(1, 2)\n",
    "trainY = tb.select(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          sentence1  \\\n",
      "0   1  In Paris , in October 1560 , he secretly met t...   \n",
      "1   2  The NBA season of 1975 -- 76 was the 30th seas...   \n",
      "2   3  There are also specific discussions , public p...   \n",
      "3   4  When comparable rates of flow can be maintaine...   \n",
      "4   5  It is the seat of Zerendi District in Akmola R...   \n",
      "\n",
      "                                           sentence2  label  \n",
      "0  In October 1560 , he secretly met with the Eng...      0  \n",
      "1  The 1975 -- 76 season of the National Basketba...      1  \n",
      "2  There are also public discussions , profile sp...      0  \n",
      "3  The results are high when comparable flow rate...      1  \n",
      "4  It is the seat of the district of Zerendi in A...      1  \n"
     ]
    }
   ],
   "source": [
    "#read in the csv files \n",
    "\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep='\\t')\n",
    "dev = pd.read_csv(\"dev.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"test.tsv\", sep='\\t')\n",
    "\n",
    "print(train[:5])\n",
    "\n",
    "train['title1_tokenized'] = \\\n",
    "    train.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "train['title2_tokenized'] = \\\n",
    "    train.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "dev['title1_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "dev['title2_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "test['title1_tokenized'] = \\\n",
    "    test.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "test['title2_tokenized'] = \\\n",
    "    test.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "#train_corpus_x1=tb.select(1)\n",
    "#train_corpus_x2=tb.select(2)\n",
    "#test_corpus_x1=testTb.select(1)\n",
    "#test_corpus_x2=testTb.select(2)\n",
    "#corpus = pd.concat([train_corpus_x1, train_corpus_x2, test_corpus_x1, test_corpus_x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98802\n",
      "130802\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary\n",
    "\n",
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = keras \\\n",
    "    .preprocessing \\\n",
    "    .text \\\n",
    "    .Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "train_corpus_x1 = train.title1_tokenized\n",
    "train_corpus_x2 = train.title2_tokenized\n",
    "train_corpus = pd.concat([\n",
    "    train_corpus_x1, train_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(train_corpus)\n",
    "tokenizer.texts_to_sequences(train_corpus)\n",
    "x1_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x1)\n",
    "x2_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x2)\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dev_corpus_x1 = dev.title1_tokenized\n",
    "dev_corpus_x2 = dev.title2_tokenized\n",
    "dev_corpus = pd.concat([\n",
    "    dev_corpus_x1, dev_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(dev_corpus)\n",
    "tokenizer.texts_to_sequences(dev_corpus)\n",
    "x1_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x1)\n",
    "x2_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x2)\n",
    "\n",
    "\n",
    "test_corpus_x1 = test.title1_tokenized\n",
    "test_corpus_x2 = test.title2_tokenized\n",
    "test_corpus = pd.concat([\n",
    "    test_corpus_x1, test_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(test_corpus)\n",
    "tokenizer.texts_to_sequences(test_corpus)\n",
    "x1_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x1)\n",
    "x2_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   43,\n",
       "           8,    7,   97,    6, 6066, 5611, 3080,    2,  446,   29, 6910,\n",
       "           4,    5, 3542,  683,   49, 3108, 1221,    4, 4527, 2922, 3890,\n",
       "          10,    1,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   22,  131,\n",
       "        2253,   10, 1628,    4, 2550,   47,  275,   61,   22,  224,  108,\n",
       "        3874,    5,  141,    1, 1968,    6,    1,   67,  683,   34, 1742,\n",
       "          10,  280,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    4,  120,  151,    2,    1, 1180, 1172,  198,\n",
       "           6, 5608,  905,    2,    2,    1, 3980,  304,   15,   32,  269,\n",
       "        2334, 2052,    3]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padding and one-hot\n",
    "\n",
    "max_seq_len1 = max([\n",
    "    len(seq) for seq in x1_train])\n",
    "print(max_seq_len1)   #36\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 36  #better to have words covered than uncovered\n",
    "x1_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x1_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x1_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x2_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "y_train = train.label\n",
    "\n",
    "y_train = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_train, num_classes=2)\n",
    "\n",
    "\n",
    "y_dev = dev.label\n",
    "\n",
    "y_dev = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_dev, num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "y_test = test.label\n",
    "\n",
    "y_test = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_test, num_classes=2)\n",
    "\n",
    "x1_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "----------\n",
      "(49401, 36)\n",
      "(49401, 36)\n",
      "(49401, 2)\n",
      "(98802,)\n",
      "----------\n",
      "(8000, 36)\n",
      "(8000, 36)\n",
      "(8000, 2)\n",
      "(16000,)\n",
      "Test Set\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "print(\"-\" * 10)\n",
    "print(np.shape(x1_train))\n",
    "print(np.shape(x2_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(train_corpus))\n",
    "\n",
    "print(\"-\" * 10)\n",
    "print(np.shape(x1_test))\n",
    "print(np.shape(x2_test))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(test_corpus))\n",
    "\n",
    "print(\"Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34723\n"
     ]
    }
   ],
   "source": [
    "NUM_EMBEDDING_DIM = 100\n",
    "print(len(word_index)+1)\n",
    "embedding_matrix = np.zeros((len(word_index)+1, NUM_EMBEDDING_DIM))\n",
    "\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese with GLoVE\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    " #rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 36 #how long one sentence is\n",
    "\n",
    " #this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(len(word_index)+1,\n",
    "                            NUM_EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = LSTM(NUM_LSTM_UNITS)\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "history = model.fit(x=[x1_train, x2_train], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=([x1_test, x2_test], y_test),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Siamese\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    " #rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 36 #how long one sentence is\n",
    "\n",
    " #this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM, mask_zero=True)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = LSTM(NUM_LSTM_UNITS)\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "history = model.fit(x=[x1_train, x2_train], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=([x1_test, x2_test], y_test),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 36)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 36)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 36, 256)      2560000     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          394240      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            1026        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,955,266\n",
      "Trainable params: 2,955,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM?\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 36 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_Wiki', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 20 07:14:21 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   46C    P8    13W / 200W |    582MiB /  8118MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 49401 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "49401/49401 [==============================] - 24s 490us/step - loss: 0.6810 - acc: 0.5756 - val_loss: 0.6828 - val_acc: 0.5647\n",
      "Epoch 2/20\n",
      "49401/49401 [==============================] - 22s 443us/step - loss: 0.6465 - acc: 0.6136 - val_loss: 0.6885 - val_acc: 0.5613\n",
      "Epoch 3/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.6301 - acc: 0.6273 - val_loss: 0.6907 - val_acc: 0.5649\n",
      "Epoch 4/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.6196 - acc: 0.6311 - val_loss: 0.6993 - val_acc: 0.5541\n",
      "Epoch 5/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.5915 - acc: 0.6041 - val_loss: 0.7082 - val_acc: 0.5154\n",
      "Epoch 6/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.5356 - acc: 0.6087 - val_loss: 0.7020 - val_acc: 0.5073\n",
      "Epoch 7/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.4830 - acc: 0.6650 - val_loss: 0.7580 - val_acc: 0.5275\n",
      "Epoch 8/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.4245 - acc: 0.7078 - val_loss: 0.8279 - val_acc: 0.5215\n",
      "Epoch 9/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.6524 - acc: 0.5790 - val_loss: 0.6931 - val_acc: 0.5576\n",
      "Epoch 10/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.6931 - acc: 0.5581 - val_loss: 0.6931 - val_acc: 0.5576\n",
      "Epoch 11/20\n",
      "49401/49401 [==============================] - 22s 442us/step - loss: 0.6931 - acc: 0.5581 - val_loss: 0.6931 - val_acc: 0.5576\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "history = model.fit(x=[x1_train, x2_train], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[earlyStopping, mcp_save], validation_data=([x1_dev, x2_dev], y_dev),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(\n",
    "    [x1_test, x2_test])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(len(predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3536\n"
     ]
    }
   ],
   "source": [
    "real1=test.sentence1\n",
    "real2=test.sentence2\n",
    "realCat=test.label\n",
    "no = []\n",
    "err1 = []\n",
    "err2 = []\n",
    "wrongCat = []\n",
    "\n",
    "\n",
    "for x in range(8000):\n",
    "    if (np.argmax(predicts[x])!=(test.label[x])):\n",
    "        no=np.append(no, x)\n",
    "        err1=np.append(err1, real1[x])\n",
    "        err2=np.append(err2, real2[x])\n",
    "        wrongCat = np.append(wrongCat, realCat[x])\n",
    "print(len(wrongCat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>classification</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0   </td> <td>This was a series of nested angular standards , so that  ...</td> <td>This was a series of nested polar scales , so that measu ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>His father emigrated to Missouri in 1868 but returned wh ...</td> <td>His father emigrated to America in 1868 , but returned w ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>In January 2011 , the Deputy Secretary General of FIBA A ...</td> <td>In January 2011 , FIBA Asia deputy secretary general Hag ...</td> <td>1             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>Steiner argued that , in the right circumstances , the s ...</td> <td>Steiner held that the spiritual world can be researched  ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>Luciano Williames Dias ( born July 25 , 1970 ) is a Braz ...</td> <td>Luciano Williames Dias ( born 25 July 1970 ) is a former ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6   </td> <td>The smallest number that can be represented in two posit ...</td> <td>The smallest number that can be represented as a sum of  ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8   </td> <td>The Villa Pesquera facilities are owned by the Municipal ...</td> <td>The facilities of Villa Pesquera are operated by the Mun ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11  </td> <td>He appeared as General Tao in the Amazon - Show `` The M ...</td> <td>He appeared as General Onoda in the Amazon - Show `` The ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>To get there , take the Marine Drive from the Lions Gate ...</td> <td>To get there , take Marine Drive west from the Lions Gat ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>17  </td> <td>For ideal gases , the molar volume is given by the ideal ...</td> <td>For ideal gases the molar volume is given by the standar ...</td> <td>0             </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (3869 rows omitted)</p>"
      ],
      "text/plain": [
       "id   | sent1                                                        | sent2                                                        | classification\n",
       "0    | This was a series of nested angular standards , so that  ... | This was a series of nested polar scales , so that measu ... | 0\n",
       "1    | His father emigrated to Missouri in 1868 but returned wh ... | His father emigrated to America in 1868 , but returned w ... | 0\n",
       "2    | In January 2011 , the Deputy Secretary General of FIBA A ... | In January 2011 , FIBA Asia deputy secretary general Hag ... | 1\n",
       "3    | Steiner argued that , in the right circumstances , the s ... | Steiner held that the spiritual world can be researched  ... | 0\n",
       "4    | Luciano Williames Dias ( born July 25 , 1970 ) is a Braz ... | Luciano Williames Dias ( born 25 July 1970 ) is a former ... | 0\n",
       "6    | The smallest number that can be represented in two posit ... | The smallest number that can be represented as a sum of  ... | 0\n",
       "8    | The Villa Pesquera facilities are owned by the Municipal ... | The facilities of Villa Pesquera are operated by the Mun ... | 0\n",
       "11   | He appeared as General Tao in the Amazon - Show `` The M ... | He appeared as General Onoda in the Amazon - Show `` The ... | 0\n",
       "14   | To get there , take the Marine Drive from the Lions Gate ... | To get there , take Marine Drive west from the Lions Gat ... | 0\n",
       "17   | For ideal gases , the molar volume is given by the ideal ... | For ideal gases the molar volume is given by the standar ... | 0\n",
       "... (3869 rows omitted)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis = Table()\n",
    "\n",
    "\n",
    "error_analysis.with_column(\"id\", no, \"sent1\", err1, \"sent2\", err2, \"classification\", wrongCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-678b5e28ff37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclearer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sent1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sent2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'error_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "clearer = error_analysis.take(\"sent1\", \"sent2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_with_glove.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_with_glove.h5\")        ##first attempt\n",
    "print(\"Saved model to disk\")           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding layer output dimension is arbitrary?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitize(\"I like, hue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 18 06:50:50 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   46C    P8     8W / 200W |    719MiB /  8118MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible optimization strats:\n",
    "\n",
    "#tokenization without punctuation aka modify the dictionary\n",
    "#tweak MAX_SEQUENCE_LENGTH \n",
    "#masking\n",
    "#NUM_EMBEDDING_DIMENSION\n",
    "#\"optimizer\" in the compile function\n",
    "#loss function\n",
    "#a different activation function?\n",
    "#sth other than word level tokenization?\n",
    "#train on other databases?\n",
    "#pretrained word embedding\n",
    "#check errors on the test set?\n",
    "#model attention seq2seq\n",
    "#GLOVE dimension modification\n",
    "#more sanitization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model adaptation: https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-3-%E6%AD%A5%E9%A9%9F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://paperswithcode.com/paper/multi-task-deep-neural-networks-for-natural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempts: with self trained word embedder, glove embedder, zero masking, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We randomly select 5,000 paraphrases and 5,000 non-paraphrases as the dev set, and sample\n",
    "#another 5,000 paraphrases and 5,000 non-paraphrases as the\n",
    "#test set. We keep the remaining instances as the training set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
