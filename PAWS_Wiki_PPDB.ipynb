{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sentence1</th> <th>sentence2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>In Paris , in October 1560 , he secretly met the English ...</td> <td>In October 1560 , he secretly met with the English ambas ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>The NBA season of 1975 -- 76 was the 30th season of the  ...</td> <td>The 1975 -- 76 season of the National Basketball Associa ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>There are also specific discussions , public profile deb ...</td> <td>There are also public discussions , profile specific dis ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>When comparable rates of flow can be maintained , the re ...</td> <td>The results are high when comparable flow rates can be m ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>It is the seat of Zerendi District in Akmola Region .       </td> <td>It is the seat of the district of Zerendi in Akmola region .</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (49396 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sentence1</th> <th>sentence2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>Bradd Crellin represented BARLA Cumbria on a tour of Aus ...</td> <td>Bradd Crellin also represented BARLA Great Britain on a  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>They were there to enjoy us and they were there to pray  ...</td> <td>They were there for us to enjoy and they were there for  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>After the end of the war in June 1902 , Higgins left Sou ...</td> <td>In August , after the end of the war in June 1902 , Higg ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>From the merger of the Four Rivers Council and the Audub ...</td> <td>Shawnee Trails Council was formed from the merger of the ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>The group toured extensively and became famous in Israel ...</td> <td>The group toured extensively and was famous in Israel an ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (7995 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sentence1</th> <th>sentence2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>This was a series of nested angular standards , so that  ...</td> <td>This was a series of nested polar scales , so that measu ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>His father emigrated to Missouri in 1868 but returned wh ...</td> <td>His father emigrated to America in 1868 , but returned w ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>In January 2011 , the Deputy Secretary General of FIBA A ...</td> <td>In January 2011 , FIBA Asia deputy secretary general Hag ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>Steiner argued that , in the right circumstances , the s ...</td> <td>Steiner held that the spiritual world can be researched  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>Luciano Williames Dias ( born July 25 , 1970 ) is a Braz ...</td> <td>Luciano Williames Dias ( born 25 July 1970 ) is a former ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (7995 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_Tb = Table()\n",
    "\n",
    "\n",
    "dev_Tb = Table()\n",
    "test_Tb=Table()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"dataset/PAWS_Wiki/train.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        train_Tb=train_Tb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "train_Tb.show(5)\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"dataset/PAWS_Wiki/dev.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        dev_Tb=dev_Tb.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "dev_Tb.show(5)\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "with open(\"dataset/PAWS_Wiki/test.tsv\", 'r', encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(4):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        test_Tb=test_Tb.with_columns(list1[0][ele], list2[ele])\n",
    "        \n",
    "test_Tb.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdb_Tb=Table.read_table(\"dataset/ppdb/sanitized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train_Tb.column(\"id\")\n",
    "train_sen1=train_Tb.column(\"sentence1\")\n",
    "train_sen2=train_Tb.column(\"sentence2\")  #PAWS_QQP\n",
    "train_row = train_Tb.num_rows\n",
    "dev_id=dev_Tb.column(\"id\")\n",
    "dev_row=dev_Tb.num_rows\n",
    "dev_sen1=dev_Tb.column(\"sentence1\")\n",
    "dev_sen2=dev_Tb.column(\"sentence2\")\n",
    "test_id=test_Tb.column(\"id\")\n",
    "test_row=test_Tb.num_rows\n",
    "test_sen1=test_Tb.column(\"sentence1\")\n",
    "test_sen2=test_Tb.column(\"sentence2\")\n",
    "train_label = train_Tb.column(\"label\")\n",
    "dev_label=dev_Tb.column(\"label\")\n",
    "test_label=test_Tb.column(\"label\")\n",
    "\n",
    "phrase = ppdb_Tb.column(\"PHRASE\")\n",
    "paraphrase=ppdb_Tb.column(\"PARAPHRASE\")   #ppdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most valuable \n",
      " 's most \n",
      " are generally \n",
      " are generally \n",
      " are generally \n",
      " are generally \n",
      " are generally \n",
      " are generally \n",
      " most popular \n",
      " taken part in \n",
      " even human \n",
      " years later \n",
      " highly significant \n",
      " passed away \n",
      " passed \n",
      " two years \n",
      " previously published \n",
      " some time \n",
      " world 's \n",
      " logistics support \n",
      " resolve the \n",
      " resolve the \n",
      " resolve the \n",
      " secondary schools in \n",
      " only possible \n",
      " to verify \n",
      " and historical \n",
      " and historical \n",
      " very hot \n",
      " since then \n",
      " two years \n",
      " around the world \n",
      " around the world \n",
      " very long \n",
      " very long \n",
      " very nice \n",
      " very nice \n",
      " table of contents \n",
      " , representing the \n",
      " and supported \n",
      " 've created \n",
      " later in life \n",
      " well received \n",
      " well received \n",
      " received \n",
      " years later \n",
      " two years \n",
      " second place \n",
      " primary school \n",
      " reached agreement \n",
      " second place \n",
      " nearly four \n",
      " first time \n",
      " very poor \n",
      " two years \n",
      " nuclear power plants \n",
      " nuclear power \n",
      " nuclear power \n",
      " relationships are \n",
      " the southern part \n",
      " are typically \n",
      " are typically \n",
      " are typically \n",
      " are typically \n",
      " are typically \n",
      " are typically \n",
      " located close to \n",
      " the northern part \n",
      " first time \n",
      " negotiations \n",
      " destroyed \n",
      " reached agreement \n",
      " airport is \n",
      " at the beginning of the \n",
      " at the beginning of the \n",
      " the beginning of the \n",
      " the beginning of the \n",
      " at the beginning of \n",
      " at the beginning of \n",
      " at the beginning of \n",
      " the beginning of \n",
      " at the beginning of the \n",
      " at the beginning of the \n",
      " beginning of the \n",
      " at the beginning of the \n",
      " children and adolescents \n",
      " and adolescents \n",
      " since then \n",
      " very similar \n",
      " put aside \n",
      " most attractive \n",
      " one of the \n",
      " , together with \n",
      " seventy years \n",
      " years later \n",
      " two years \n",
      " the quantity of \n",
      " as were the \n",
      " , as were the \n",
      " , as were the \n",
      " as were the \n",
      " collaboration with \n",
      " collaboration with \n",
      " shortly after \n",
      " was lost \n",
      " some time \n",
      " second place \n",
      " the second place \n",
      " to verify \n",
      " were permitted to \n",
      " very quickly \n",
      " greater than \n",
      " quite similar \n",
      " the capital city of \n",
      " the capital city \n",
      " capital city of \n",
      " capital city \n",
      " years later \n",
      " later , after \n",
      " providing the \n",
      " very small \n",
      " once again \n",
      " once again \n",
      " shortly after \n",
      " the city of \n",
      " and historical \n",
      " and historical \n",
      " most recently \n",
      " was begun in \n",
      " broken off \n",
      " first time \n",
      " very religious \n",
      " cooperation with \n",
      " shortly after \n",
      " shortly after \n",
      " 's group \n",
      " public authorities \n",
      " people and injured \n",
      " passed away \n",
      " passed \n",
      " years later \n",
      " the contents of \n",
      " the contents \n",
      " contents of \n",
      " 's life \n",
      " ministers , \n",
      " located close to \n",
      " the second largest \n",
      " second largest \n",
      " the second \n",
      " after the resignation \n",
      " after the resignation of \n",
      " third and final \n",
      " the 20th century \n",
      " of the 20th century \n",
      " of the 20th \n",
      " very close \n",
      " being held \n",
      " to supervise \n",
      " very simple \n",
      " simple \n",
      " in the year 2000 \n",
      " for ten \n",
      " 's school \n",
      " become a \n",
      " men 's \n",
      " took part in \n",
      " that took part in \n",
      " took part in this \n",
      " established in 2005 \n",
      " the relationship between \n",
      " relationship between the \n",
      " relationship between \n",
      " the relationship \n",
      " for the relationship between \n",
      " return home \n",
      " to return home \n",
      " the historic \n",
      " second place \n",
      " began in the \n",
      " most common \n",
      " reached an agreement with \n",
      " an agreement with \n",
      " reached an agreement \n",
      " reached an agreement \n",
      " an agreement \n",
      " in rural areas \n",
      " urban areas \n",
      " very close \n",
      " center of the \n",
      " men 's \n",
      " common sense \n",
      " financially supported \n",
      " 's group \n",
      " three times \n",
      " of the city of \n",
      " of the city of \n",
      " the city of \n",
      " to start \n"
     ]
    }
   ],
   "source": [
    "index_list=[]\n",
    "PPDB_id = []\n",
    "sent1=[]\n",
    "sent2=[]\n",
    "para_list1=[]\n",
    "para_list2=[]\n",
    "labeling = []\n",
    "\n",
    "ans = []\n",
    "for x in range(len(train_id)):   #index of PAWS_Wiki training set\n",
    "    \n",
    "    for z in range(len(phrase)):  #index of PPDB\n",
    "        if (phrase[z] in train_sen1[x] and paraphrase[z] in train_sen2[x]):\n",
    "            print(phrase[z])\n",
    "            index_list=np.append(index_list, x)\n",
    "            PPDB_id=np.append(PPDB_id, z)\n",
    "            sent1=np.append(sent1, train_sen1[x])\n",
    "            sent2=np.append(sent2, train_sen2[x])\n",
    "            para_list1=np.append(para_list1, phrase[z])\n",
    "            para_list2=np.append(para_list2, paraphrase[z])\n",
    "            labeling = np.append(labeling, train_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset = Table().with_column(\"TRAIN_PAWS_Wiki_id\", index_list, \"PPDB_id\", PPDB_id, \"sent1\", sent1, \"sent2\", sent2, \"paraphrase1\", para_list1, \"paraphrase2\", para_list2, \"label\", labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.to_csv(\"dataset/Phrase_Level/PAWS_Wiki/PPDB_PAWS_Wiki_TRAIN.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "PPDB_id = []\n",
    "sent1=[]\n",
    "sent2=[]\n",
    "para_list1=[]\n",
    "para_list2=[]\n",
    "labeling = []\n",
    "\n",
    "ans = []\n",
    "for x in range(len(dev_id)):   #index of PAWS_Wiki dev set\n",
    "    \n",
    "    for z in range(len(phrase)):  #index of PPDB\n",
    "        if (phrase[z] in dev_sen1[x] and paraphrase[z] in dev_sen2[x]):\n",
    "            print(phrase[z])\n",
    "            index_list=np.append(index_list, x)\n",
    "            PPDB_id=np.append(PPDB_id, z)\n",
    "            sent1=np.append(sent1, dev_sen1[x])\n",
    "            sent2=np.append(sent2, dev_sen2[x])\n",
    "            para_list1=np.append(para_list1, phrase[z])\n",
    "            para_list2=np.append(para_list2, paraphrase[z])\n",
    "            labeling = np.append(labeling, dev_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset = Table().with_column(\"DEV_PAWS_Wiki_id\", index_list, \"PPDB_id\", PPDB_id, \"sent1\", sent1, \"sent2\", sent2, \"paraphrase1\", para_list1, \"paraphrase2\", para_list2, \"label\", labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "PPDB_id = []\n",
    "sent1=[]\n",
    "sent2=[]\n",
    "para_list1=[]\n",
    "para_list2=[]\n",
    "labeling = []\n",
    "\n",
    "ans = []\n",
    "for x in range(len(test_id)):   #index of PAWS_Wiki test set\n",
    "    \n",
    "    for z in range(len(phrase)):  #index of PPDB\n",
    "        if (phrase[z] in test_sen1[x] and paraphrase[z] in test_sen2[x]):\n",
    "            print(phrase[z])\n",
    "            index_list=np.append(index_list, x)\n",
    "            PPDB_id=np.append(PPDB_id, z)\n",
    "            sent1=np.append(sent1, test_sen1[x])\n",
    "            sent2=np.append(sent2, test_sen2[x])\n",
    "            para_list1=np.append(para_list1, phrase[z])\n",
    "            para_list2=np.append(para_list2, paraphrase[z])\n",
    "            labeling = np.append(labeling, test_label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dataset = Table().with_column(\"TEST_PAWS_Wiki_id\", index_list, \"PPDB_id\", PPDB_id, \"sent1\", sent1, \"sent2\", sent2, \"paraphrase1\", para_list1, \"paraphrase2\", para_list2, \"label\", labeling)\n",
    "phrase_dataset.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_TRAIN-Copy1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_TRAIN.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV-Copy1.csv\")\n",
    "dataframe.to_csv(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>DEV_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>84905.0 </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality </td> <td> quality    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>129607.0</td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality </td> <td> quality    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>72492.0 </td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with   </td> <td> start with </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>366448.0</td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with   </td> <td> start with </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (96 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list1=[]\n",
    "list2=[]\n",
    "\n",
    "label_data = Table()\n",
    "with open(\"dataset/Phrase_Level/PPDB_PAWS_QQP_DEV.tsv\", 'r') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        \n",
    "        list1.append(row) #pairs start at index 1, with id, setence1, sentence2, label, respectively.\n",
    "     \n",
    "    for y in range(6):\n",
    "        temp=[]\n",
    "        for x in range(1, len(list1)):\n",
    "            temp.append(list1[x][y])\n",
    "            \n",
    "        list2.append(temp)\n",
    "\n",
    "    for ele in range(len(list2)):\n",
    "        label_data=label_data.with_columns(list1[0][ele], list2[ele])\n",
    "\n",
    "\n",
    "\n",
    "label_data.show(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sent1=label_data.column(\"sent1\")\n",
    "sent2=label_data.column(\"sent2\")\n",
    "para1=label_data.column(\"paraphrase1\")\n",
    "para2=label_data.column(\"paraphrase2\")\n",
    "\n",
    "gg = [x.split() for x in sent1]\n",
    "hh = [x.split() for x in sent2]\n",
    "ii = [x.split() for x in para1]\n",
    "jj = [x.split() for x in para2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[]\n",
    "for x in range(len(gg)):\n",
    "    labels1.append(spit_label(gg[x], ii[x], len(ii[x]),len(ii[x]), []))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=[]\n",
    "for x in range(len(hh)):\n",
    "    labels2.append(spit_label(hh[x], jj[x], len(jj[x]),len(jj[x]), []))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined1=[]\n",
    "for x in labels1:\n",
    "    joined1.append(\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined2=[]\n",
    "for x in labels2:\n",
    "    joined2.append(\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>DEV_PAWS_QQP_id</th> <th>PPDB_id</th> <th>sent1</th> <th>sent2</th> <th>paraphrase1</th> <th>paraphrase2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>84905.0 </td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality         </td> <td> quality     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3.0            </td> <td>129607.0</td> <td>b\"Why ca n't countries afford high quality products , bu ...</td> <td>b\"Why ca n't countries afford China 's high quality prod ...</td> <td> high quality         </td> <td> quality     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>72492.0 </td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with           </td> <td> start with  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11.0           </td> <td>366448.0</td> <td>b'How do I start learning electronic music production ?  ...</td> <td>b'How do I begin learning electronic music production ?  ...</td> <td> begin with           </td> <td> start with  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>22.0           </td> <td>543619.0</td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td>b\"I 'm currently working for a Big 4 as an Advanced Tax  ...</td> <td> much better          </td> <td> much        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25.0           </td> <td>487239.0</td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td>b'In Nevada when pulling out of a parking lot , can you  ...</td> <td> far left             </td> <td> left        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29.0           </td> <td>284980.0</td> <td>b\"What are the reasons for SAARC 's failure as regional  ...</td> <td>b\"What are the reasons for SAARC 's failure as common or ...</td> <td> economic cooperation </td> <td> cooperation </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>56.0           </td> <td>459668.0</td> <td>b'I want to be a child psychologist , what qualification ...</td> <td>b'I want to become a child psychologist , what qualifica ...</td> <td> become one           </td> <td> be          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>57.0           </td> <td>71262.0 </td> <td>b'Why are beautiful girls so rude all the time ? I saw a ...</td> <td>b'Why are rude girls so beautiful all the time ? I saw a ...</td> <td> very rude            </td> <td> rude        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>57.0           </td> <td>494710.0</td> <td>b'Why are beautiful girls so rude all the time ? I saw a ...</td> <td>b'Why are rude girls so beautiful all the time ? I saw a ...</td> <td> go away              </td> <td> away        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (90 rows omitted)</p>"
      ],
      "text/plain": [
       "DEV_PAWS_QQP_id | PPDB_id  | sent1                                                        | sent2                                                        | paraphrase1            | paraphrase2\n",
       "3.0             | 84905.0  | b\"Why ca n't countries afford high quality products , bu ... | b\"Why ca n't countries afford China 's high quality prod ... |  high quality          |  quality\n",
       "3.0             | 129607.0 | b\"Why ca n't countries afford high quality products , bu ... | b\"Why ca n't countries afford China 's high quality prod ... |  high quality          |  quality\n",
       "11.0            | 72492.0  | b'How do I start learning electronic music production ?  ... | b'How do I begin learning electronic music production ?  ... |  begin with            |  start with\n",
       "11.0            | 366448.0 | b'How do I start learning electronic music production ?  ... | b'How do I begin learning electronic music production ?  ... |  begin with            |  start with\n",
       "22.0            | 543619.0 | b\"I 'm currently working for a Big 4 as an Advanced Tax  ... | b\"I 'm currently working for a Big 4 as an Advanced Tax  ... |  much better           |  much\n",
       "25.0            | 487239.0 | b'In Nevada when pulling out of a parking lot , can you  ... | b'In Nevada when pulling out of a parking lot , can you  ... |  far left              |  left\n",
       "29.0            | 284980.0 | b\"What are the reasons for SAARC 's failure as regional  ... | b\"What are the reasons for SAARC 's failure as common or ... |  economic cooperation  |  cooperation\n",
       "56.0            | 459668.0 | b'I want to be a child psychologist , what qualification ... | b'I want to become a child psychologist , what qualifica ... |  become one            |  be\n",
       "57.0            | 71262.0  | b'Why are beautiful girls so rude all the time ? I saw a ... | b'Why are rude girls so beautiful all the time ? I saw a ... |  very rude             |  rude\n",
       "57.0            | 494710.0 | b'Why are beautiful girls so rude all the time ? I saw a ... | b'Why are rude girls so beautiful all the time ? I saw a ... |  go away               |  away\n",
       "... (90 rows omitted)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data=label_data.with_columns(\"labels1\", joined1, \"labels2\", joined2)\n",
    "label_data=label_data.to_df()\n",
    "label_data.to_csv(\"dataset/Phrase_Level/LABELED_PAWS_QQP_DEV.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def spit_label(split_sent, para_split, ori_length, length, listy):\n",
    "       \n",
    "    \n",
    "        if para_split[0]==split_sent[0]:\n",
    "            \n",
    "            if ori_length==1:\n",
    "                listy.append(\"S\")\n",
    "                for x in range(len(split_sent)-1):\n",
    "                    listy.append(\"O\")\n",
    "                return listy    \n",
    "            \n",
    "            elif ori_length==length:\n",
    "                listy.append(\"B\")\n",
    "                return spit_label(split_sent[1:], para_split[1:], ori_length, length-1, listy)\n",
    "                \n",
    "            elif length==1:\n",
    "                listy.append(\"E\")\n",
    "                for x in range(len(split_sent)-1):\n",
    "                    listy.append(\"O\")\n",
    "                return listy\n",
    "            \n",
    "            else:\n",
    "                listy.append(\"I\")\n",
    "                return spit_label(split_sent[1:], para_split[1:], ori_length, length-1, listy)\n",
    "                \n",
    "        else:\n",
    "            listy.append(\"O\")\n",
    "            return spit_label(split_sent[1:], para_split, ori_length, length, listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=\"\".join(\"he \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
