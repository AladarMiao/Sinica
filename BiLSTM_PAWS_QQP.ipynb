{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "#config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.Session(config=config)) \n",
    "import re\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from keras.callbacks import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(string):\n",
    "    words = string.split(' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  9 02:04:50 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   46C    P8     8W / 200W |    185MiB /  8118MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          sentence1  \\\n",
      "0   1  b'What were the major effects of the cambodia ...   \n",
      "1   2  b\"The guy I 'm dating never texts me and I fee...   \n",
      "\n",
      "                                           sentence2  label  \\\n",
      "0  b'What were the major effects of the Iquique e...      0   \n",
      "1  b\"The guy I 'm dating never wants me and I fee...      0   \n",
      "\n",
      "                                    title1_tokenized  \\\n",
      "0  [b'What, were, the, major, effects, of, the, c...   \n",
      "1  [b\"The, guy, I, 'm, dating, never, texts, me, ...   \n",
      "\n",
      "                                    title2_tokenized  \n",
      "0  [b'What, were, the, major, effects, of, the, I...  \n",
      "1  [b\"The, guy, I, 'm, dating, never, wants, me, ...  \n"
     ]
    }
   ],
   "source": [
    "#read csv\n",
    "\n",
    "train = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_train.tsv\", sep='\\t')\n",
    "dev = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_dev_and_test.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"dataset/PAWS_QQP/PAWS_QQP_dev_and_test.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "train['title1_tokenized'] = \\\n",
    "    train.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "train['title2_tokenized'] = \\\n",
    "    train.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "dev['title1_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "dev['title2_tokenized'] = \\\n",
    "    dev.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "test['title1_tokenized'] = \\\n",
    "    test.loc[:, 'sentence1'] \\\n",
    "         .apply(sanitize)\n",
    "test['title2_tokenized'] = \\\n",
    "    test.loc[:, 'sentence2'] \\\n",
    "         .apply(sanitize)\n",
    "\n",
    "\n",
    "print(dev[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                          sentence1  \\\n",
      "0   1  b'What were the major effects of the cambodia ...   \n",
      "1   2  b\"The guy I 'm dating never texts me and I fee...   \n",
      "\n",
      "                                           sentence2  label  \\\n",
      "0  b'What were the major effects of the Iquique e...      0   \n",
      "1  b\"The guy I 'm dating never wants me and I fee...      0   \n",
      "\n",
      "                                    title1_tokenized  \\\n",
      "0  [b'What, were, the, major, effects, of, the, c...   \n",
      "1  [b\"The, guy, I, 'm, dating, never, texts, me, ...   \n",
      "\n",
      "                                    title2_tokenized  \n",
      "0  [b'What, were, the, major, effects, of, the, I...  \n",
      "1  [b\"The, guy, I, 'm, dating, never, wants, me, ...  \n"
     ]
    }
   ],
   "source": [
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23726\n",
      "26402\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = keras \\\n",
    "    .preprocessing \\\n",
    "    .text \\\n",
    "    .Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "train_corpus_x1 = train.title1_tokenized\n",
    "train_corpus_x2 = train.title2_tokenized\n",
    "train_corpus = pd.concat([\n",
    "    train_corpus_x1, train_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(train_corpus)\n",
    "tokenizer.texts_to_sequences(train_corpus)\n",
    "x1_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x1)\n",
    "x2_train = tokenizer \\\n",
    "    .texts_to_sequences(train_corpus_x2)\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dev_corpus_x1 = dev.title1_tokenized\n",
    "dev_corpus_x2 = dev.title2_tokenized\n",
    "dev_corpus = pd.concat([\n",
    "    dev_corpus_x1, dev_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(dev_corpus)\n",
    "tokenizer.texts_to_sequences(dev_corpus)\n",
    "x1_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x1)\n",
    "x2_dev = tokenizer \\\n",
    "    .texts_to_sequences(dev_corpus_x2)\n",
    "\n",
    "\n",
    "test_corpus_x1 = test.title1_tokenized\n",
    "test_corpus_x2 = test.title2_tokenized\n",
    "test_corpus = pd.concat([\n",
    "    test_corpus_x1, test_corpus_x2])\n",
    "#corpus.shape\n",
    "tokenizer.fit_on_texts(test_corpus)\n",
    "tokenizer.texts_to_sequences(test_corpus)\n",
    "x1_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x1)\n",
    "x2_test = tokenizer \\\n",
    "    .texts_to_sequences(test_corpus_x2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "print(tokenizer.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_seq_len1 = max([\n",
    "    len(seq) for seq in x1_train])\n",
    "print(max_seq_len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1850,\n",
       "        215,    9,  101,  689,  297, 4957,   71,    5,    9,  120,   47,\n",
       "        108,   28,   54, 1034,   84,   71,   52,   50,    9,  166,  259,\n",
       "        108,  718,   71,  108, 1037,   71,    5,  853,   71,   20,   59,\n",
       "         12,    9,  120,   79,  103,   19], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50  #better to have words covered than uncovered\n",
    "x1_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_train = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_train, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x1_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x2_dev = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_dev, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "x1_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x1_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x2_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(x2_test, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "y_train = train.label\n",
    "\n",
    "y_train = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_train, num_classes=2)\n",
    "\n",
    "\n",
    "y_dev = dev.label\n",
    "\n",
    "y_dev = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_dev, num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "y_test = test.label\n",
    "\n",
    "y_test = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_test, num_classes=2)\n",
    "\n",
    "x1_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cos similarity value to last elem of word embedding\n",
    "x1_test_cos=[]\n",
    "x2_test_cos=[]\n",
    "x1_train_cos=[]\n",
    "x2_train_cos=[]\n",
    "x1_dev_cos=[]\n",
    "x2_dev_cos=[]\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "def cos_sim(vec1, vec2):\n",
    "    return (1 - spatial.distance.cosine(vec1, vec2))\n",
    "\n",
    "for x in range(len(y_train)):\n",
    "    \n",
    "    \n",
    "    cos_train=cos_sim(x1_train[x], x2_train[x])\n",
    "    \n",
    "    \n",
    "    x1_train_cos.append(np.append(x1_train[x], cos_train))\n",
    "    x2_train_cos.append(np.append(x2_train[x], cos_train))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for x in range(len(y_test)):\n",
    "    cos_dev=cos_sim(x1_dev[x], x2_dev[x])\n",
    "    cos_test=cos_sim(x1_test[x], x2_test[x])\n",
    "    x1_test_cos.append(np.append(x1_test[x], cos_test))\n",
    "    x2_test_cos.append(np.append(x2_test[x], cos_test))\n",
    "    x1_dev_cos.append(np.append(x1_dev[x], cos_dev))\n",
    "    x2_dev_cos.append(np.append(x2_dev[x], cos_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11863"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1_train_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11,\n",
       "  153,\n",
       "  2,\n",
       "  265,\n",
       "  521,\n",
       "  10,\n",
       "  2,\n",
       "  1441,\n",
       "  758,\n",
       "  8,\n",
       "  5,\n",
       "  30,\n",
       "  12,\n",
       "  236,\n",
       "  521,\n",
       "  112,\n",
       "  3,\n",
       "  2,\n",
       "  4981,\n",
       "  758,\n",
       "  6,\n",
       "  4982,\n",
       "  1],\n",
       " [1850,\n",
       "  215,\n",
       "  9,\n",
       "  101,\n",
       "  689,\n",
       "  297,\n",
       "  4957,\n",
       "  71,\n",
       "  5,\n",
       "  9,\n",
       "  120,\n",
       "  47,\n",
       "  108,\n",
       "  28,\n",
       "  54,\n",
       "  1034,\n",
       "  84,\n",
       "  71,\n",
       "  52,\n",
       "  50,\n",
       "  9,\n",
       "  166,\n",
       "  259,\n",
       "  108,\n",
       "  718,\n",
       "  71,\n",
       "  108,\n",
       "  1037,\n",
       "  71,\n",
       "  5,\n",
       "  853,\n",
       "  71,\n",
       "  20,\n",
       "  59,\n",
       "  12,\n",
       "  9,\n",
       "  120,\n",
       "  79,\n",
       "  103,\n",
       "  19]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 50, 256)      2560000     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 256)          394240      embedding_4[0][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            1026        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,955,266\n",
      "Trainable params: 2,955,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM?\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP.h5', save_best_only=True,  verbose=1, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 51, 256)      2560000     input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 256)          394240      embedding_6[0][0]                \n",
      "                                                                 embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4           dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,954,244\n",
      "Trainable params: 2,954,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity\n",
    "\n",
    "\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "merged = dot(\n",
    "    [top_output, bm_output], \n",
    "    axes=1, normalize = True)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_cos_sim.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 51, 256)      2560000     input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 256)          394240      embedding_14[0][0]               \n",
      "                                                                 embedding_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 512)          0           bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            1026        concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,955,266\n",
      "Trainable params: 2,955,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM with last cos_sim element concatenated?\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 51 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "\n",
    "\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS))\n",
    "\n",
    "top_output = shared_lstm(top_embedded)\n",
    "\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='sigmoid')\n",
    "predictions = dense(merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_concat_sim_cos.h5', save_best_only=True,  verbose=1, monitor='val_acc', mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           (None, 51)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 51, 256)      2560000     input_79[0][0]                   \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_50 (Bidirectional (None, 51, 256)      394240      embedding_46[0][0]               \n",
      "                                                                 embedding_46[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_64 (SeqSelfA (None, 51, 256)      16449       bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_65 (SeqSelfA (None, 51, 256)      16449       bidirectional_50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 51, 512)      0           seq_self_attention_64[0][0]      \n",
      "                                                                 seq_self_attention_65[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 26112)        0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Dense (Dense)                   (None, 2)            52226       flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,039,364\n",
      "Trainable params: 3,039,364\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#attention model\n",
    "\n",
    "#last elem cos sim + attention\n",
    "\n",
    "NUM_CLASSES=2 #boolean; 1 or 0\n",
    "\n",
    "#rough estimate\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 51 #how long one sentence is\n",
    "\n",
    "#this is arbitrary?\n",
    "\n",
    "NUM_LSTM_UNITS = 128 #output dimension\n",
    "\n",
    "\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "top_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),    #this is the first sentence\n",
    "    dtype='int32')\n",
    "\n",
    "bm_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ),   #this is the second\n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "top_embedded = embedding_layer(\n",
    "    top_input)\n",
    "bm_embedded = embedding_layer(\n",
    "    bm_input)\n",
    "\n",
    "shared_LSTM = Bidirectional(LSTM(NUM_LSTM_UNITS, return_sequences=True)) \n",
    "\n",
    "top_output = shared_LSTM(top_embedded)\n",
    "\n",
    "bm_output = shared_LSTM(bm_embedded)\n",
    "\n",
    "\n",
    "\n",
    "top_attention_output = SeqSelfAttention(attention_activation='sigmoid')(top_output)\n",
    "\n",
    "bm_attention_output = SeqSelfAttention(attention_activation='sigmoid')(bm_output)\n",
    "\n",
    "\n",
    "merged = concatenate(\n",
    "    [top_attention_output, bm_attention_output], \n",
    "    axis=-1)\n",
    "\n",
    "#new_merged = keras.layers.Reshape((-1, 2))(merged)\n",
    "\n",
    "flatten_merged = Flatten()(merged)\n",
    "\n",
    "dense =  Dense(\n",
    "    units=2, name='Dense')\n",
    "predictions = dense(flatten_merged)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=[top_input, bm_input], \n",
    "    outputs=[predictions])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "mcp_save = ModelCheckpoint('BiLSTM_PAWS_QQP_simcos_attention.h5', save_best_only=True,  verbose=1, monitor='val_acc', mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-d4a3c8b17be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#y_train.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (2)"
     ]
    }
   ],
   "source": [
    "#y_train.shape\n",
    "temp = np.reshape(merged, (-1,2))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11863 samples, validate on 669 samples\n",
      "Epoch 1/30\n",
      "11863/11863 [==============================] - 15s 1ms/step - loss: 6.5231 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71749, saving model to BiLSTM_PAWS_QQP_simcos_attention.h5\n",
      "Epoch 2/30\n",
      "11863/11863 [==============================] - 8s 685us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.71749\n",
      "Epoch 3/30\n",
      "11863/11863 [==============================] - 8s 686us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71749\n",
      "Epoch 4/30\n",
      "11863/11863 [==============================] - 8s 687us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.71749\n",
      "Epoch 5/30\n",
      "11863/11863 [==============================] - 8s 688us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71749\n",
      "Epoch 6/30\n",
      "11863/11863 [==============================] - 8s 687us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71749\n",
      "Epoch 7/30\n",
      "11863/11863 [==============================] - 8s 685us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71749\n",
      "Epoch 8/30\n",
      "11863/11863 [==============================] - 8s 686us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71749\n",
      "Epoch 9/30\n",
      "11863/11863 [==============================] - 8s 686us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.71749\n",
      "Epoch 10/30\n",
      "11863/11863 [==============================] - 8s 687us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.71749\n",
      "Epoch 11/30\n",
      "11863/11863 [==============================] - 8s 686us/step - loss: 5.0883 - acc: 0.6843 - val_loss: 4.5535 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.71749\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x1_train_cos, x2_train_cos], y=y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[earlyStopping, mcp_save], validation_data=([x1_dev_cos, x2_dev_cos], y_dev),\n",
    "    \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BiLSTM_PAWS_QQP_concat_sim_cos.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicts = model.predict(\n",
    "    [x1_train_cos, x2_train_cos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11863"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[:5]\n",
    "len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075276068448116\n"
     ]
    }
   ],
   "source": [
    "real1=train.sentence1\n",
    "real2=train.sentence2\n",
    "realCat=train.label\n",
    "no = []\n",
    "err1 = []\n",
    "err2 = []\n",
    "wrongCat = []\n",
    "\n",
    "\n",
    "for x in range(len(predicts)):\n",
    "    if (np.argmax(predicts[x])!=(train.label[x])):\n",
    "       \n",
    "            no=np.append(no, x)\n",
    "            err1=np.append(err1, real1[x])\n",
    "            err2=np.append(err2, real2[x])\n",
    "            wrongCat = np.append(wrongCat, realCat[x])\n",
    "    \n",
    "        \n",
    "print(1-(len(wrongCat)/len(predicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19  </td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35  </td> <td>b'How do I prepare for cognizant campus placement online ...</td> <td>b\"How do I prepare for Cognizant 's online campus placem ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53  </td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61  </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>78  </td> <td>b'Which CPU should I buy , an Intel or an AMD ?'            </td> <td>b'Which CPU should I buy , an AMD or an Intel ?'            </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>93  </td> <td>b'If one were in the desert with no water except one gal ...</td> <td>b'If one were in the desert with no water except one gal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>139 </td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>143 </td> <td>b\"`` Is 1 month too early to say `` I love you `` ? What ...</td> <td>b'Is 1 month too early to say I love you ? What is the n ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>147 </td> <td>b'I filled the wrong AADHAR enrollment number in the mai ...</td> <td>b'I filled the wrong AADHAR enrollment number in the onl ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>149 </td> <td>b\"I 'm liberal , how would you convince me to be conserv ...</td> <td>b\"I 'm a 'Conservative ' , how would you convince me to  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>150 </td> <td>b'What is the worst thing that has happened to you for b ...</td> <td>b'What is the best thing that has happened to you for be ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>183 </td> <td>b'Can the pro-choice position provide a scientific and r ...</td> <td>b'Can the pro-choice position provide a rational and sci ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>192 </td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>204 </td> <td>b'If you had a chance to become someone else who would y ...</td> <td>b'If you had a chance to be someone else who would you b ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>208 </td> <td>b'What are the top grade levels and titles at different  ...</td> <td>b'What are the different grade levels and titles at top  ...</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>214 </td> <td>b'How similar is Cantonese to Putonghua ?'                  </td> <td>b'How is Cantonese similar to Putonghua ?'                  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>232 </td> <td>b'Also plz share the best material to learn selenium tes ...</td> <td>b'Also please share the best material to learn selenium  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>247 </td> <td>b'What is the difference between standard deviation and  ...</td> <td>b'What is the difference between mean deviation and stan ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>256 </td> <td>b'Why do tamil people hate tamilian brahmin so much ?'      </td> <td>b'Why do tamilian people hate tamil brahmin so much ?'      </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>265 </td> <td>b'What is difference between the extended version and th ...</td> <td>b'What is difference between the theatrical version and  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>273 </td> <td>b'I have got admission from IIM Lucknow and am expecting ...</td> <td>b'I have got admission from IIM Lucknow and I am expecti ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>274 </td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>284 </td> <td>b'Should I shower with cold water or warm water after wo ...</td> <td>b'Should I shower with warm water or cold water after wo ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>295 </td> <td>b'How do you describe a poor and a rich person ?'           </td> <td>b'How do you describe a rich and a poor person ?'           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>317 </td> <td>b\"If Pakistan does controlled a large part of Kashmir ca ...</td> <td>b\"If Pakistan has controlled a large part of Kashmir cal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1067 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0.7873219253\n",
    "error_analysis = Table()\n",
    "\n",
    "\n",
    "error_analysis = error_analysis.with_column(\"id\", no, \"sent1\", err1, \"sent2\", err2, \"label\", wrongCat)\n",
    "\n",
    "\n",
    "#false POSITIVE: swap two words\n",
    "#false negative: swap two specific nouns\n",
    "error_analysis.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>sent1</th> <th>sent2</th> <th>label</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>13  </td> <td>b'Are Indian IT services companies like Tech Mahindra/ W ...</td> <td>b'Are Indian IT services companies like Wipro/TCS/Tech . ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14  </td> <td>b'Is nuclear energy renewable energy ?'                     </td> <td>b\"`` Is nuclear energy `` renewable energy `` ? ''\"         </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19  </td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>b'Thinking to start reading novels.Suggest which books t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21  </td> <td>b'How can I make an android app using Python 3 ? Is ther ...</td> <td>b'How can I develop an android app using Python 3 ? Is t ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28  </td> <td>b\"What does the phrase 'Do you feel me ' mean ?\"            </td> <td>b\"What does the phrase `Do you feel me'mean ?\"              </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29  </td> <td>b'What are some unexpected things first-time visitors to ...</td> <td>b'What are some unexpected things , first-time visitors  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35  </td> <td>b'How do I prepare for cognizant campus placement online ...</td> <td>b\"How do I prepare for Cognizant 's online campus placem ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53  </td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>b'How does quality of life in Vancouver compare to that  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61  </td> <td>b'I have only a very nice startup idea but I m not good  ...</td> <td>b'I have only a very good startup idea but I m not nice  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>78  </td> <td>b'Which CPU should I buy , an Intel or an AMD ?'            </td> <td>b'Which CPU should I buy , an AMD or an Intel ?'            </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>93  </td> <td>b'If one were in the desert with no water except one gal ...</td> <td>b'If one were in the desert with no water except one gal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>139 </td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>b'My H1B petition was approved in 2008 but I never got i ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>143 </td> <td>b\"`` Is 1 month too early to say `` I love you `` ? What ...</td> <td>b'Is 1 month too early to say I love you ? What is the n ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>147 </td> <td>b'I filled the wrong AADHAR enrollment number in the mai ...</td> <td>b'I filled the wrong AADHAR enrollment number in the onl ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>183 </td> <td>b'Can the pro-choice position provide a scientific and r ...</td> <td>b'Can the pro-choice position provide a rational and sci ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>192 </td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>b\"Why do we feel like we should break something when we  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>204 </td> <td>b'If you had a chance to become someone else who would y ...</td> <td>b'If you had a chance to be someone else who would you b ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>214 </td> <td>b'How similar is Cantonese to Putonghua ?'                  </td> <td>b'How is Cantonese similar to Putonghua ?'                  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>232 </td> <td>b'Also plz share the best material to learn selenium tes ...</td> <td>b'Also please share the best material to learn selenium  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>247 </td> <td>b'What is the difference between standard deviation and  ...</td> <td>b'What is the difference between mean deviation and stan ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>256 </td> <td>b'Why do tamil people hate tamilian brahmin so much ?'      </td> <td>b'Why do tamilian people hate tamil brahmin so much ?'      </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>265 </td> <td>b'What is difference between the extended version and th ...</td> <td>b'What is difference between the theatrical version and  ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>273 </td> <td>b'I have got admission from IIM Lucknow and am expecting ...</td> <td>b'I have got admission from IIM Lucknow and I am expecti ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>274 </td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>b'How to activate Whatsapp on my new iPhone with old num ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>284 </td> <td>b'Should I shower with cold water or warm water after wo ...</td> <td>b'Should I shower with warm water or cold water after wo ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>295 </td> <td>b'How do you describe a poor and a rich person ?'           </td> <td>b'How do you describe a rich and a poor person ?'           </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>317 </td> <td>b\"If Pakistan does controlled a large part of Kashmir ca ...</td> <td>b\"If Pakistan has controlled a large part of Kashmir cal ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>333 </td> <td>b'Which Bollywood movie has a well crafted , very effect ...</td> <td>b'Which Bollywood movie has a very effective , well craf ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>354 </td> <td>b'I want to do biotechnology from abroad which country s ...</td> <td>b'I want to do biotechnology from abroad which country s ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>355 </td> <td>b'Which study pattern should I follow to prepare for COS ...</td> <td>b'Which pattern of study I should follow to prepare COST ...</td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (876 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_analysis.where(\"label\", are.equal_to(1)).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
